<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Eduardo E. R. Junior &amp; Matheus H. Sales" />


<title>Aprendizado de Máquina</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/yeti.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
div.sourceCode {
  overflow-x: visible;
}
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="_style.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>

<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 45px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 50px;
  margin-top: -50px;
}

.section h2 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h3 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h4 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h5 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h6 {
  padding-top: 50px;
  margin-top: -50px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Listas
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="lista1.html">Lista 1</a>
    </li>
  </ul>
</li>
<li class="dropdown-header">Seminário</li>
<li class="dropdown-header">Pôster</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://jreduardo.github.io/">Eduardo Jr's website</a>
</li>
<li>
  <a href="https://github.com/JrEduardo/ce064-ml">
    <span class="fa fa-github-alt fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Aprendizado de Máquina</h1>
<h3 class="subtitle"><em>UFMG EST171 - 1ª Lista de exercícios</em></h3>
<h4 class="author"><em>Eduardo E. R. Junior &amp; Matheus H. Sales</em></h4>
<h4 class="date"><em>12 de setembro de 2016</em></h4>

</div>

<div id="TOC">
<ul>
<li><a href="#exercicio-1">Exercício 1</a></li>
<li><a href="#exercicio-2">Exercício 2</a></li>
<li><a href="#material-suplementar">Material suplementar</a></li>
</ul>
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Para construir as matrizes do modelo (exercício 1)
buildX &lt;-<span class="st"> </span>function(x, p) {
    X &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">1</span>, <span class="dt">nrow =</span> <span class="kw">length</span>(x))
    v &lt;-<span class="st"> </span><span class="dv">2</span> *<span class="st"> </span>pi *<span class="st"> </span>x
    for (p in <span class="dv">1</span>:p) {
        m &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">xs =</span> <span class="kw">sin</span>(v *<span class="st"> </span>p), <span class="dt">xc =</span> <span class="kw">cos</span>(v *<span class="st"> </span>p))
        <span class="kw">colnames</span>(m) =<span class="st"> </span><span class="kw">paste0</span>(<span class="kw">colnames</span>(m), p)
        X &lt;-<span class="st"> </span><span class="kw">cbind</span>(X, m)
    }
    <span class="kw">return</span>(X)
}

## Para seleção de amostra MCMC de apenas alguns parâmetros
select_pars &lt;-<span class="st"> </span>function(sample, pars) {
    if (!<span class="kw">is.mcmc.list</span>(sample)) {
        sample &lt;-<span class="st"> </span><span class="kw">as.mcmc.list</span>(sample)
    }
    out &lt;-<span class="st"> </span><span class="kw">lapply</span>(sample, function(x) {
        sel &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;</span><span class="ch">\\</span><span class="st">[[0-9]+</span><span class="ch">\\</span><span class="st">]&quot;</span>, <span class="dt">repl =</span> <span class="st">&quot;&quot;</span>, <span class="kw">colnames</span>(x))
        x[, sel %in%<span class="st"> </span>pars]
    })
    <span class="kw">return</span>(<span class="kw">as.mcmc</span>(out))
}

## Para partição de uma base de dados em dados de treinamento,
## validação, teste, etc.
mysplit &lt;-<span class="st"> </span>function(data, <span class="dt">percent =</span> <span class="ot">NA</span>, <span class="dt">nfolds =</span> <span class="ot">NA</span>,
                    <span class="dt">nobs =</span> <span class="ot">NA</span>, <span class="dt">seed =</span> <span class="ot">NULL</span>) {
    if (<span class="kw">sum</span>(<span class="kw">is.na</span>(<span class="kw">c</span>(percent, nfolds, nobs))) !=<span class="st"> </span><span class="dv">2</span>) {
        <span class="kw">stop</span>(<span class="st">&quot;Utilize um e apenas um dos argumentos&quot;</span>)
    }
    n &lt;-<span class="st"> </span><span class="kw">nrow</span>(data)
    if (!<span class="kw">sum</span>(<span class="kw">is.na</span>(percent))) {
        if (<span class="kw">sum</span>(percent) !=<span class="st"> </span><span class="dv">1</span>) {
            <span class="kw">stop</span>(<span class="st">&quot;Os percentuais em cada dobra devem somar 1!&quot;</span>)
        }
        p &lt;-<span class="st"> </span>percent
        folds &lt;-<span class="st"> </span>n *<span class="st"> </span>p
    }
    if (!<span class="kw">is.na</span>(nfolds)) {
        if (nfolds &gt;<span class="st"> </span>n) {
            <span class="kw">stop</span>(<span class="kw">paste0</span>(<span class="st">&quot;O número de dobras não deve exceder o &quot;</span>,
                       <span class="st">&quot;tamanho da amostra (n=&quot;</span>, n, <span class="st">&quot;)!&quot;</span>))
        }
        p &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>/nfolds, nfolds)
        folds &lt;-<span class="st"> </span>n *<span class="st"> </span>p
    }
    if (!<span class="kw">sum</span>(<span class="kw">is.na</span>(nobs))) {
        if (<span class="kw">sum</span>(nobs) !=<span class="st"> </span>n) {
            <span class="kw">stop</span>(<span class="kw">paste0</span>(<span class="st">&quot;O número de observações em cada dobra deve &quot;</span>,
                       <span class="st">&quot;somar &quot;</span>, n, <span class="st">&quot;!&quot;</span>))
        }
        folds &lt;-<span class="st"> </span>nobs
    }
    if (!<span class="kw">is.null</span>(seed)) {
        <span class="kw">set.seed</span>(seed)
    }
    folds &lt;-<span class="st"> </span><span class="kw">round</span>(folds)
    while (<span class="kw">sum</span>(folds) !=<span class="st"> </span>n) {
        g &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">length</span>(folds), <span class="dv">1</span>)
        if (<span class="kw">sum</span>(folds) &lt;<span class="st"> </span>n) {
            folds[g] &lt;-<span class="st"> </span>folds[g] +<span class="st"> </span><span class="dv">1</span>
        } else {
            folds[g] &lt;-<span class="st"> </span>folds[g] -<span class="st"> </span><span class="dv">1</span>
        }
    }
    out &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="dt">length =</span> <span class="kw">length</span>(folds))
    for (i in <span class="dv">1</span>:<span class="kw">length</span>(folds)) {
        index &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">nrow</span>(data), <span class="dt">size =</span> folds[i])
        out[[i]] &lt;-<span class="st"> </span>data[index, ]
        data &lt;-<span class="st"> </span>data[-index, ]
    }
    <span class="kw">return</span>(out)
}</code></pre></div>
<div id="exercicio-1" class="section level2">
<h2>Exercício 1</h2>
<blockquote>
<p>Baixe os dados worldDevelopmentIndicators.csv, que contém os dados do PIB per capita (X) e a expectativa de vida (Y) de diversos países. O objetivo é criar preditores de Y com base em X. Em aula vimos como isso pode ser feito através de polinômios. Aqui, faremos isso via expansões de Fourier.</p>
</blockquote>
<p>Como são dados bidimensionais uma representação gráfica é realizada na . Note que não há um padrão cíclico aparente que justifique a utilização de expansões via séries de Fourier, porém essas serão utilizadas para ilustração das técnicas apresentadas na disciplina.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dados &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;./data/worldDevelopmentIndicators.csv&quot;</span>,
                     <span class="dt">header =</span> <span class="ot">TRUE</span>, <span class="dt">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="dt">quote =</span> <span class="st">&quot;</span><span class="ch">\&quot;</span><span class="st">&quot;</span>,
                     <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>)
<span class="kw">names</span>(dados) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;country&quot;</span>, <span class="st">&quot;y&quot;</span>, <span class="st">&quot;x&quot;</span>)

<span class="kw">xyplot</span>(y ~<span class="st"> </span>x, <span class="dt">data =</span> dados,
       <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">&quot;g&quot;</span>, <span class="st">&quot;p&quot;</span>, <span class="st">&quot;smooth&quot;</span>),
       <span class="dt">xlab =</span> <span class="st">&quot;PIB per capita&quot;</span>,
       <span class="dt">ylab =</span> <span class="st">&quot;Expectativa de vida&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center">
<img src="lista1_files/figure-html/descritiva-1.png" alt="Dispersão do dados" width="864" />
<p class="caption">
Dispersão do dados
</p>
</div>
<hr />
<blockquote>
<p><em><strong>a)</strong> Normalize a covariável de modo que <span class="math inline">\(x \in (0, 1)\)</span>. Para isso, faça <span class="math inline">\(x = \frac{x-xmin}{xmax-xmin}\)</span>, onde <span class="math inline">\(xmin\)</span> e <span class="math inline">\(xmax\)</span> são os valores mínimo e máximo de <span class="math inline">\(x\)</span> segundo a amostra usada.</em></p>
</blockquote>
<p>Após realizada a padronização da variável conforme indicação do exercício, apresenta-se seu comportamento via densidade estimada na , note a forte assimetria da variável com quase 75% dos seus valores abaixo de 0.1.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dados &lt;-<span class="st"> </span><span class="kw">transform</span>(dados, <span class="dt">x =</span> (x -<span class="st"> </span><span class="kw">min</span>(x)) /<span class="st"> </span>(<span class="kw">max</span>(x) -<span class="st"> </span><span class="kw">min</span>(x)))
## summary(dados$x)
<span class="kw">densityplot</span>(~x, <span class="dt">data =</span> dados, <span class="dt">grid =</span> <span class="ot">TRUE</span>)</code></pre></div>
<div class="figure" style="text-align: center">
<img src="lista1_files/figure-html/densx-1.png" alt="Densidade estimada do PIB per capita padronizado" width="864" />
<p class="caption">
Densidade estimada do PIB per capita padronizado
</p>
</div>
<hr />
<blockquote>
<p><em><strong>b)</strong> Usando o método dos mínimos quadrados e a validação cruzada do tipo leave-one-out, estime o erro quadrático médio das regressões <span class="math display">\[g(x) = \sum_{i=1}^p \beta_{si} sin(2 \pi i x) + \beta_{ci} cos(2 \pi
  i x), \qquad \text{para } p = 1, 2, \ldots, 30\]</span></em></p>
</blockquote>
<p>Para o ajuste e estimação do erro quadrático médio de tais regressões utilizou-se o software R com a rotina descrita abaixo:</p>
<ol style="list-style-type: decimal">
<li>Ajuste dos modelos, tendo os modelos armazenados outras medidas de qualidade podem ser extraídas.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">X &lt;-<span class="st"> </span><span class="kw">cbind</span>()
models &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="dv">30</span>)
v &lt;-<span class="st"> </span><span class="dv">2</span> *<span class="st"> </span>pi *<span class="st"> </span>dados$x

## Ajuste todos os modelos
for (p in <span class="dv">1</span>:<span class="dv">30</span>) {
    m &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">xs =</span> <span class="kw">sin</span>(v *<span class="st"> </span>p), <span class="dt">xc =</span> <span class="kw">cos</span>(v *<span class="st"> </span>p))
    <span class="kw">colnames</span>(m) =<span class="st"> </span><span class="kw">paste0</span>(<span class="kw">colnames</span>(m), p)
    X &lt;-<span class="st"> </span><span class="kw">cbind</span>(X, m)
    models[[p]] &lt;-<span class="st"> </span><span class="kw">lm</span>(y ~<span class="st"> </span>X, <span class="dt">data =</span> dados)
}</code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Calcula o erro quadrático para cada observação retirada do ajuste e posteriormente predita pelos <span class="math inline">\(p\)</span> modelos. Mantém apenas os erros quadráticos para avaliação de seu comportamento, uma vez que resumos, como a média podem ser obtidos facilmente. Os valores preditos de cada observação também são armazenados.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Calcula o erro quadrático de cada observação para cada modelo via
## cross-validation leave-one-out
results &lt;-<span class="st"> </span><span class="kw">lapply</span>(models, function(modelo) {
    n &lt;-<span class="st"> </span><span class="kw">nrow</span>(modelo$model)
    eqs &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;numeric&quot;</span>, <span class="dt">length =</span> n)
    pred &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;numeric&quot;</span>, <span class="dt">length =</span> n)
    for (i in <span class="dv">1</span>:n) {
        ## obs &lt;- as.data.frame(modelo$model[i, ])
        ## mod &lt;- update(modelo, data = modelo$model[-i, ])
        ## pred[i] &lt;- predict(mod, newdata = obs)
        obs &lt;-<span class="st"> </span>modelo$model$y[i]
        mod &lt;-<span class="st"> </span><span class="kw">with</span>(modelo$model,
                    <span class="kw">.lm.fit</span>(<span class="dt">x =</span> <span class="kw">cbind</span>(<span class="dv">1</span>, X[-i, ]), <span class="dt">y =</span> y[-i]))
        pred[i] &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>, modelo$model$X)[i, ] %*%<span class="st"> </span>mod$coefficients
        eqs[i] &lt;-<span class="st"> </span>(obs -<span class="st"> </span>pred[i])^<span class="dv">2</span>
    }
    <span class="kw">list</span>(<span class="dt">eqs =</span> eqs, <span class="dt">pred =</span> pred)
})

## Extraindo os erros quadráticos médios
eqms.mean &lt;-<span class="st"> </span><span class="kw">sapply</span>(results, function(x) <span class="kw">mean</span>(x[[<span class="st">&quot;eqs&quot;</span>]]))</code></pre></div>
<p>Caso prefiro funções prontas, existe um pacote no R, <code>cvTools</code> que realiza a validação cruzada do tipo leave-one-out, além de outras estratégias.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##-------------------------------------------
## Pra quem gosta de pacotes ...
<span class="kw">library</span>(cvTools)
teste &lt;-<span class="st"> </span><span class="kw">sapply</span>(models, function(x) <span class="kw">cvLm</span>(x, <span class="dt">cost =</span> mspe, <span class="dt">K =</span> <span class="dv">211</span>)$cv)
teste ==<span class="st"> </span>eqms.mean
##-------------------------------------------</code></pre></div>
<hr />
<blockquote>
<p><em><strong>c)</strong> Plote o gráfico do risco estimado vs <span class="math inline">\(p\)</span>. Qual o valor de <span class="math inline">\(p\)</span> escolhido? Denotaremos ele por <span class="math inline">\(p_{esc}\)</span></em></p>
</blockquote>
<p>Primeiramente para a escolha do <span class="math inline">\(p\)</span> decidiu-se por avaliar o comportamento dos erros em cada modelo ajustado. Essa avaliação é exibida na , onde apresenta-se os erros quadráticos para cada observação em cada modelo na escala logarítmica com a indicação da média, mediana e quartis. Note que o comportamento dos erros é bastante assimétrico, manifestando essa assimetria também na escala logarítmica. Além da assimetria muitos pontos discrepantes são observados, principalmente nos modelos mais complexos (<span class="math inline">\(p &gt; 12\)</span>). Devido a isso decidiu-se por apresentar, além do erro quadrático médio, erro quadrático mediano, pela mediana ser uma medida resumo menos sensível a dados extremos.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">eqs &lt;-<span class="st"> </span><span class="kw">do.call</span>(cbind, <span class="kw">lapply</span>(results, function(x) x[[<span class="st">&quot;eqs&quot;</span>]]))
<span class="kw">colnames</span>(eqs) &lt;-<span class="st"> </span><span class="dv">1</span>:<span class="dv">30</span>
eqs &lt;-<span class="st"> </span><span class="kw">stack</span>(<span class="kw">as.data.frame</span>(eqs))
eqs$ind &lt;-<span class="st"> </span><span class="kw">as.integer</span>(<span class="kw">as.character</span>(eqs$ind))

## Exibição gráfica
##  -- Legenda
key &lt;-<span class="st"> </span><span class="kw">list</span>(
    <span class="dt">corner =</span> <span class="kw">c</span>(<span class="fl">0.05</span>, <span class="fl">0.9</span>),
    <span class="dt">points =</span> <span class="kw">list</span>(<span class="dt">pch =</span> <span class="dv">15</span>),
    <span class="dt">text =</span> <span class="kw">list</span>(<span class="kw">expression</span>(Média~dos~<span class="kw">log</span>(eqs)))
)
##  -- Gráfico
<span class="kw">xyplot</span>(<span class="kw">log</span>(values) ~<span class="st"> </span><span class="kw">factor</span>(ind),
       <span class="dt">data =</span> eqs,
       <span class="dt">key =</span> key,
       <span class="dt">xlab =</span> <span class="st">&quot;p&quot;</span>,
       <span class="dt">ylab =</span> <span class="kw">expression</span>(<span class="kw">log</span>(Erro~Quadrático)),
       <span class="dt">panel =</span> function(x, y, subscripts, ...) {
           <span class="kw">panel.grid</span>(<span class="dt">h =</span> -<span class="dv">1</span>, <span class="dt">v =</span> <span class="dv">0</span>)
           <span class="kw">panel.xyplot</span>(<span class="dt">x =</span> <span class="kw">as.integer</span>(x) -<span class="st"> </span><span class="fl">0.1</span>, <span class="dt">y =</span> y,
                        <span class="dt">col =</span> <span class="st">&quot;gray60&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.7</span>, <span class="dt">cex =</span> <span class="fl">0.8</span>, ...)
           <span class="kw">panel.bwplot</span>(<span class="dt">x =</span> <span class="kw">as.integer</span>(x) +<span class="st"> </span><span class="fl">0.1</span>, <span class="dt">y =</span> y,
                        <span class="dt">horizontal =</span> <span class="ot">FALSE</span>, <span class="dt">box.width =</span> <span class="fl">0.4</span>)
           means &lt;-<span class="st"> </span><span class="kw">tapply</span>(y, x, mean)
           <span class="kw">panel.points</span>(<span class="dt">y =</span> means, <span class="dt">x =</span> <span class="kw">unique</span>(<span class="kw">as.integer</span>(x)) +<span class="st"> </span><span class="fl">0.1</span>,
                        <span class="dt">pch =</span> <span class="dv">15</span>)
       })</code></pre></div>
<div class="figure" style="text-align: center">
<img src="lista1_files/figure-html/boxplotseqs-1.png" alt="Distribuição empírica dos logarítmos dos erros quadráticos médios para cada um dos p modelos" width="864" />
<p class="caption">
Distribuição empírica dos logarítmos dos erros quadráticos médios para cada um dos p modelos
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Medidas de qualidade de predição/ajuste
eqms.median &lt;-<span class="st"> </span><span class="kw">sapply</span>(results, function(x) <span class="kw">median</span>(x[[<span class="st">&quot;eqs&quot;</span>]]))
aics &lt;-<span class="st"> </span><span class="kw">sapply</span>(models, AIC)

## Agrupando as medidas
medidas &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">p =</span> <span class="dv">1</span>:<span class="dv">30</span>,
                      <span class="dt">mean =</span> eqms.mean,
                      <span class="dt">median =</span> eqms.median,
                      <span class="dt">aics =</span> aics)

## Indicação dos melhores modelos
medidas.min &lt;-<span class="st"> </span><span class="kw">sapply</span>(medidas[, -<span class="dv">1</span>], which.min)

## Representação gráfica
da &lt;-<span class="st"> </span>reshape2::<span class="kw">melt</span>(medidas, <span class="dt">id.vars =</span> <span class="st">&quot;p&quot;</span>)
fl &lt;-<span class="st"> </span><span class="kw">expression</span>(<span class="kw">E</span>(<span class="kw">EQM</span>(model[p])),
                 <span class="kw">Md</span>(<span class="kw">EQM</span>(model[p])),
                 <span class="kw">AIC</span>(model[p]))
<span class="kw">xyplot</span>(<span class="kw">log</span>(value) ~<span class="st"> </span>p |<span class="st"> </span>variable,
       <span class="dt">type =</span> <span class="st">&quot;S&quot;</span>,
       <span class="dt">data =</span> da,
       <span class="dt">ylab =</span> <span class="kw">expression</span>(<span class="kw">log</span>(<span class="kw">hat</span>(R))),
       <span class="dt">as.table =</span> <span class="ot">TRUE</span>,
       <span class="dt">layout =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="dv">1</span>),
       <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>,
       <span class="dt">strip =</span> <span class="kw">strip.custom</span>(<span class="dt">factor.levels =</span> fl),
       <span class="dt">panel =</span> function(x, y, subscripts, ...) {
           <span class="kw">panel.grid</span>()
           <span class="kw">panel.xyplot</span>(x, y, ...)
           <span class="kw">panel.abline</span>(<span class="dt">h =</span> <span class="kw">min</span>(y, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),
                        <span class="dt">v =</span> <span class="kw">which.min</span>(y),
                        <span class="dt">lty =</span> <span class="dv">2</span>)
       })</code></pre></div>
<div class="figure" style="text-align: center">
<img src="lista1_files/figure-html/measuresfourier-1.png" alt="Medidas de qualidade de predição na escala logarítimica (linha pontilhada representa a indicação do melhor modelo)" width="864" />
<p class="caption">
Medidas de qualidade de predição na escala logarítimica (linha pontilhada representa a indicação do melhor modelo)
</p>
</div>
<p>Na  são apresentadas as medidas de qualidade de predição e ajuste para todos os <span class="math inline">\(p\)</span> modelos. São apresentados os erros quadráticos médios e medianos e também o AIC (Critério de Informação de Akaike) como uma medida mais estatística que mensura a parcimônia do modelo. As três medidas indicaram diferentes modelos sendo p = 3, 9, 10 para as medidas erro quadrático médio, erro quadrático mediano e AIC, respectivamente. Desta forma, nas análises subsequentes serão apresentados os resultados para os modelos com p = 3, 9.</p>
<hr />
<blockquote>
<p><em><strong>d)</strong> Plote os das curvas ajustadas para p = 1 ; p = <span class="math inline">\(p_{esc}\)</span> e p = 30 sob o gráfico de dispersão de X por Y. Qual curva parece mais razoável? Use um grid de valores entre 0 e 1 para isso. Como estes ajustes se comparam com o visto em aula via polinômios? Discuta</em>.</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Os modelos que serão comparados
index &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, medidas.min[<span class="dv">1</span>:<span class="dv">2</span>], <span class="dv">30</span>)

## Curva dos modelos
lista &lt;-<span class="st"> </span>models[index]
pred &lt;-<span class="st"> </span><span class="kw">lapply</span>(lista, function(modelo) {
    x =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> <span class="dv">50</span>)
    betas &lt;-<span class="st"> </span><span class="kw">coef</span>(modelo)
    X &lt;-<span class="st"> </span><span class="kw">buildX</span>(<span class="dt">x =</span> x, <span class="dt">p =</span> (<span class="kw">length</span>(betas) -<span class="st"> </span><span class="dv">1</span>)/<span class="dv">2</span>)
    out &lt;-<span class="st"> </span><span class="kw">cbind</span>(x, X %*%<span class="st"> </span>betas)
    <span class="kw">colnames</span>(out) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;x&quot;</span>, <span class="st">&quot;yhat&quot;</span>)
    out
})

<span class="kw">names</span>(pred) &lt;-<span class="st"> </span>index
da &lt;-<span class="st"> </span>plyr::<span class="kw">ldply</span>(pred, <span class="dt">.id =</span> <span class="st">&quot;model&quot;</span>)

leg &lt;-<span class="st"> </span><span class="kw">parse</span>(<span class="dt">text =</span> <span class="kw">paste0</span>(<span class="st">&quot;model[&quot;</span>, index, <span class="st">&quot;]&quot;</span>))
key &lt;-<span class="st"> </span><span class="kw">list</span>(
    <span class="dt">space =</span> <span class="st">&quot;top&quot;</span>,
    <span class="dt">column =</span> <span class="dv">2</span>,
    <span class="dt">lines =</span> <span class="kw">list</span>(<span class="dt">col =</span> cols[<span class="kw">seq_along</span>(index)], <span class="dt">lty =</span> <span class="dv">1</span>),
    <span class="dt">text =</span> <span class="kw">list</span>(leg)
)

xy1 &lt;-<span class="st"> </span><span class="kw">xyplot</span>(y ~<span class="st"> </span>x, <span class="dt">data =</span> dados,
              <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">&quot;g&quot;</span>, <span class="st">&quot;p&quot;</span>),
              <span class="dt">alpha =</span> <span class="fl">0.5</span>,
              <span class="dt">key =</span> key,
              <span class="dt">xlab =</span> <span class="st">&quot;PIB per capita (transformado)&quot;</span>,
              <span class="dt">ylab =</span> <span class="st">&quot;Expectativa de vida&quot;</span>) +
<span class="st">    </span><span class="kw">as.layer</span>(
        <span class="kw">xyplot</span>(yhat ~<span class="st"> </span>x, <span class="dt">groups =</span> model,
               <span class="dt">data =</span> da, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)
    )

xy2 &lt;-<span class="st"> </span><span class="kw">xyplot</span>(yhat ~<span class="st"> </span>x |<span class="st"> </span>model,
              <span class="dt">data =</span> da,
              <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">&quot;l&quot;</span>, <span class="st">&quot;g&quot;</span>),
              <span class="dt">layout =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>),
              <span class="dt">as.table =</span> <span class="ot">TRUE</span>,
              <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>,
              <span class="dt">strip =</span> <span class="kw">strip.custom</span>(
                  <span class="dt">factor.levels =</span> leg)) +
<span class="st">    </span><span class="kw">xyplot</span>(y ~<span class="st"> </span>x, <span class="dt">data =</span> dados, <span class="dt">alpha =</span> <span class="fl">0.6</span>)

<span class="kw">print</span>(xy1, <span class="dt">split =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dt">more =</span> <span class="ot">TRUE</span>)
<span class="kw">print</span>(xy2, <span class="dt">split =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dt">more =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center">
<img src="lista1_files/figure-html/curvefourier-1.png" alt="Curvas ajustadas. Conjuntamente no intervalo dos dados (esquerda) e individuais no interrvalo de predição (direita)." width="960" />
<p class="caption">
Curvas ajustadas. Conjuntamente no intervalo dos dados (esquerda) e individuais no interrvalo de predição (direita).
</p>
</div>
<p>Séries de Fourier são comumente utilizadas na análise de séries temporais, pois tem flexibilidade para ajustar sazonalidade, sua aplicação aos dados indicados no exemplo parece não ser adequada conforme pode ser visto na , em que os ajustes dos modelos com <span class="math inline">\(p =\)</span> 1, 3, 9, 30 são exibidos. Como não é claro um comportamento cíclico nos dados, todos os modelos ajustam ciclos de forma incorreta, sendo nos modelos para <span class="math inline">\(p\)</span> = 9 e 30 os ajustes mais discrepantes com ajuste muito incorreto, principalmente para intervalos com menos observações. Para <span class="math inline">\(p\)</span> = 1 a imposição de forma da Série de Fourier produz uma curva fora do padrão dos dados para PIB’s padronizados maiores que 0,5.</p>
<p>Assim como o ajuste por polinômios, bastante comum em modelos de regressão linear aplicados em problemas de predição, a forma do preditor linear se mantém quando não se tem muitas observações para ajuste, proporcionando assim, um péssimo poder preditivo para problemas em que a forma do preditor linear não é adequada, como é o caso deste exemplo.</p>
<hr />
<blockquote>
<p><em><strong>e) </strong> Plote o gráfico de valores preditos versus ajustados para p = 1; p = <span class="math inline">\(p_{esc}\)</span> e p = 30 (não se esqueça de usar o leave-one-out para calcular os valores preditos! Caso contrário você terá problemas de overfitting novamente). Qual p parece ser o mais razoável?</em></p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Valores preditos vs observado
lista &lt;-<span class="st"> </span>results[index]
preds &lt;-<span class="st"> </span><span class="kw">do.call</span>(cbind, <span class="kw">lapply</span>(lista, function(x) x[[<span class="st">&quot;pred&quot;</span>]]))
preds &lt;-<span class="st"> </span><span class="kw">cbind</span>(dados[, <span class="kw">c</span>(<span class="st">&quot;y&quot;</span>, <span class="st">&quot;x&quot;</span>)], preds)
<span class="kw">colnames</span>(preds) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;real&quot;</span>, <span class="st">&quot;x&quot;</span>, index)
preds &lt;-<span class="st"> </span>reshape2::<span class="kw">melt</span>(<span class="kw">as.data.frame</span>(preds), <span class="dt">id.vars =</span> <span class="kw">c</span>(<span class="st">&quot;real&quot;</span>, <span class="st">&quot;x&quot;</span>))

preds &lt;-<span class="st"> </span>preds[<span class="kw">with</span>(preds, <span class="kw">order</span>(x)), ]
xy1 &lt;-<span class="st"> </span><span class="kw">xyplot</span>(y ~<span class="st"> </span>x, <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">&quot;p&quot;</span>, <span class="st">&quot;g&quot;</span>),
              <span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">key =</span> key, <span class="dt">data =</span> dados) +
<span class="st">    </span><span class="kw">as.layer</span>(
        <span class="kw">xyplot</span>(value ~<span class="st"> </span>x,
               <span class="dt">groups =</span>  variable,
               <span class="dt">data =</span> preds,
               <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)
    )

xy2 &lt;-<span class="st"> </span><span class="kw">xyplot</span>(real ~<span class="st"> </span>value |<span class="st"> </span>variable, <span class="dt">data =</span> preds,
              <span class="dt">scales =</span> <span class="kw">list</span>(<span class="dt">x =</span> <span class="st">&quot;free&quot;</span>),
              <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">&quot;p&quot;</span>, <span class="st">&quot;g&quot;</span>),
              <span class="dt">alpha =</span> <span class="fl">0.5</span>,
              <span class="dt">as.table =</span> <span class="ot">TRUE</span>,
              <span class="dt">layout =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>),
              <span class="dt">ylab =</span> <span class="st">&quot;Observado&quot;</span>,
              <span class="dt">xlab =</span> <span class="st">&quot;Predito&quot;</span>,
              <span class="dt">strip =</span> <span class="kw">strip.custom</span>(<span class="dt">factor.levels =</span> leg),
              <span class="dt">panel =</span> function(x, y, subscripts, ...) {
                  <span class="kw">panel.xyplot</span>(x, y, ...)
                  <span class="kw">panel.abline</span>(<span class="dv">0</span>, <span class="dv">1</span>)
              })


<span class="kw">print</span>(xy1, <span class="dt">split =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dt">more =</span> <span class="ot">TRUE</span>)
<span class="kw">print</span>(xy2, <span class="dt">split =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dt">more =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center">
<img src="lista1_files/figure-html/predfourier-1.png" alt="Valores observados versus valores preditos. Traço de valores preditos (esquerda) e observados versus preditos (direita)" width="960" />
<p class="caption">
Valores observados versus valores preditos. Traço de valores preditos (esquerda) e observados versus preditos (direita)
</p>
</div>
<p>Observa-se nos gráficos dos valores preditos versus valores observados,  à esquerda, que os modelos mais complexos (<span class="math inline">\(p\)</span> = 9 e <span class="math inline">\(p\)</span> = 30) parecem produzir melhores resultados. Todavia, para alguns valores, cuja a predição é incorreta, a discrepância com relação ao valor observado é enorme, devido a imposição de sazonalidade do modelo. Isto posto, podemos interpretar estes bons resultados de predição para os modelos com <span class="math inline">\(p\)</span> = 9 e <span class="math inline">\(p\)</span> = 30 como sobreajuste, uma vez que a forma do modelo é incorreta para predição de novas observações, e o ajuste tentar interpolar as observações. Para os modelos com <span class="math inline">\(p\)</span> = 1 e <span class="math inline">\(p\)</span> = 3 observa-se claramente que há uma característica não explicada pelo modelo que prejudica as predições, novamente imposta pela forma das séries de Fourier.</p>
<hr />
<blockquote>
<p><em><strong>f) </strong> Quais vantagens e desvantagens de se usar validação cruzada do tipo leave-one-out versus o data- splitting?</em></p>
</blockquote>
<p>Para a avaliação dos modelos ajustados utilizou-se medidas da qualidade de predição baseadas em validação cruzada do tipo leave-one-out. Essa estratégia de validação cruzada é computacionalmente intensiva, pois cada modelo é reajustado <span class="math inline">\(n\)</span> vezes (neste caso <span class="math inline">\(n = 211\)</span>), tornando o procedimento mais lento. Porém ao utilizar a estratégia leave-one-out todos os dados são utilizados tanto na validação quanto no ajuste do modelo tornando os resultados gerais. Isso não ocorre quando utilizado estratégias do tipo data-splitting (holdoult ou k-fold), pois os resultados ficam condicionados a partição da base, ou seja, há a variabilidade nos resultados advinda do procedimento de partição, e.g. ao realizar novamente a avaliação dos modelos via data-splitting os resultados são, com alta probabilidade, distintos.</p>
<hr />
<blockquote>
<p><em><strong>g) </strong> Ajuste a regressão Lasso (Frequentista e Bayesiana) e discuta os resultados encontrados.</em></p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##-------------------------------------------
## Lasso Frequentista
<span class="kw">library</span>(glmnet)
m0lasso &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(<span class="dt">x =</span> X, <span class="dt">y =</span> dados$y,
                     <span class="dt">family =</span> <span class="st">&quot;gaussian&quot;</span>,
                     <span class="dt">alpha =</span> <span class="dv">1</span>, <span class="dt">nfolds =</span> <span class="dv">211</span>,
                     <span class="dt">grouped =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rjags)

model &lt;-<span class="st"> &quot;</span>
<span class="st">model {</span>
<span class="st">  ## Verossimilhanca</span>
<span class="st">  for(i in 1:n) {</span>
<span class="st">    y[i] ~ dnorm(mu[i], tau)</span>
<span class="st">    mu[i] &lt;- inprod(X[i, ], beta)</span>
<span class="st">  }</span>
<span class="st">  ## Prioris 1 ordem</span>
<span class="st">  tau ~ dgamma(.1, 1.0E-5)</span>
<span class="st">  for (j in 1:p) {</span>
<span class="st">    beta[j] ~ ddexp(0, lambda)</span>
<span class="st">  }</span>
<span class="st">  ## Prioris 2 ordem</span>
<span class="st">  lambda ~ dgamma(0.1, 0.1)</span>
<span class="st">  ## Tranformacoes</span>
<span class="st">  sigma &lt;- sqrt(1/tau)</span>
<span class="st">}</span>
<span class="st">&quot;</span>

## str(X)
data0 &lt;-<span class="st"> </span><span class="kw">list</span>(
    <span class="dt">n =</span> <span class="kw">nrow</span>(dados),
    <span class="dt">p =</span> <span class="dv">1</span> +<span class="st"> </span><span class="kw">ncol</span>(X),
    <span class="dt">y =</span> dados$y,
    <span class="dt">X =</span> <span class="kw">cbind</span>(<span class="dv">1</span>, X)
)
init0 &lt;-<span class="st"> </span><span class="kw">list</span>(
    <span class="dt">tau =</span> <span class="dv">1</span>,
    <span class="dt">beta =</span> <span class="kw">rep</span>(<span class="dv">0</span>, data0$p),
    <span class="dt">lambda =</span> m0lasso$lambda.min
)

jagsmodel &lt;-<span class="st"> </span><span class="kw">jags.model</span>(
    <span class="kw">textConnection</span>(model),
    <span class="dt">data =</span> data0,
    <span class="dt">inits =</span> init0,
    <span class="dt">n.chains =</span> <span class="dv">3</span>,
    <span class="dt">n.adapt =</span> <span class="dv">1000</span>
)

amostra &lt;-<span class="st"> </span><span class="kw">coda.samples</span>(
    jagsmodel, <span class="kw">c</span>(<span class="st">&quot;lambda&quot;</span>, <span class="st">&quot;beta&quot;</span>, <span class="st">&quot;sigma&quot;</span>, <span class="st">&quot;mu&quot;</span>),
    <span class="dt">n.iter =</span> <span class="dv">10000</span>, <span class="dt">thin =</span> <span class="dv">5</span>,
    <span class="dt">n.chains =</span> <span class="dv">3</span>,
    <span class="dt">n.adapt =</span> <span class="dv">1000</span>)</code></pre></div>
<p><strong>Ajuste via penalização Lasso</strong>: Sob essa abordagem minimiza-se a função de soma de quadrados penalizada da forma <span class="math display">\[R(\beta) =
  \sum_{i=1}^n (y_i - \underline{x}_i^t \beta)^2 - \lambda
  \sum_{j=1}^p|\beta_j|\]</span> em que <span class="math inline">\(\underline{x}_i^t=(x_{i1},x_{i2},\ldots,x_{ip})\)</span> são as covariáveis de cada observação. A escolha do <span class="math inline">\(\lambda\)</span> ótima, em geral, é realizada via validação cruzada.</p>
<p><strong>Ajuste via especificação Bayesiana</strong>: Sob o paradigma Bayesiano temos a penalização da função de verossimilhança realizada por meio de prioris dos parâmetros que são assumidas distribuições <em>Double Exponential</em> (ou Laplace) de parâmetros 0 e <span class="math inline">\(\lambda\)</span>. <span class="math display">\[\begin{gathered}
  Y \mid X \sim \text{Normal}(\underline{x}_i^t \beta, \sigma^2) \\
  \beta_j \sim \text{Laplace}(0, \lambda), \quad j = 1, 2, \ldots, p
  \end{gathered}\]</span> em que <span class="math inline">\(\underline{x}_i^t=(x_{i1},x_{i2},\ldots,x_{ip})\)</span> são as covariáveis de cada observação. Mantendo as inferências sob o paradigma bayesiano são dadas prioris para <span class="math inline">\(\sigma^2\)</span> e também, em segundo nível para <span class="math inline">\(\lambda\)</span>. Assim o tunning do parâmetro <span class="math inline">\(\lambda\)</span> é realizado via simulações MCMC, por exemplo.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Coeficientes Lasso
da.lasso &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(
    <span class="kw">matrix</span>(<span class="kw">c</span>(m0lasso$lambda.min, m0lasso$lambda.min, m0lasso$lambda.1se),
           <span class="dt">ncol =</span> <span class="dv">3</span>, <span class="dt">nrow =</span> <span class="dv">1</span>))
<span class="kw">colnames</span>(da.lasso) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;fit&quot;</span>, <span class="st">&quot;lower&quot;</span>, <span class="st">&quot;upper&quot;</span>)

## Coeficientes Bayesiano com intervalo de credibilidade HPD
amlambda &lt;-<span class="st"> </span><span class="kw">select_pars</span>(amostra, <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;lambda&quot;</span>))
amlambda &lt;-<span class="st"> </span><span class="kw">as.mcmc</span>(<span class="kw">do.call</span>(c, amlambda))
summary.lambda &lt;-<span class="st"> </span><span class="kw">summary</span>(amlambda)

da.bayes &lt;-<span class="st"> </span><span class="kw">HPDinterval</span>(amlambda)
da.bayes &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="st">&quot;fit&quot;</span> =<span class="st"> </span>summary.lambda$statistics[<span class="st">&quot;Mean&quot;</span>],
                  <span class="kw">as.data.frame</span>(da.bayes))

## Junta e apresenta as estimativas via lasso e os intervalos de
## credibilidade via abordagem bayesiana
da.all &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">cbind</span>(da.bayes, <span class="dt">pars =</span> <span class="dv">1</span>, <span class="dt">model =</span> <span class="st">&quot;bayes&quot;</span>),
                <span class="kw">cbind</span>(da.lasso, <span class="dt">pars =</span> <span class="dv">1</span>, <span class="dt">model =</span> <span class="st">&quot;lasso&quot;</span>))
da.all &lt;-<span class="st"> </span>da.all[<span class="kw">with</span>(da.all, <span class="kw">order</span>(pars, model)), ]

key &lt;-<span class="st"> </span><span class="kw">list</span>(
    ## corner = c(0.1, 0.9),
    <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>, <span class="dt">divide =</span> <span class="dv">1</span>,
    <span class="dt">columns =</span> <span class="dv">2</span>,
    <span class="dt">lines =</span> <span class="kw">list</span>(<span class="dt">pch =</span> <span class="kw">c</span>(<span class="dv">15</span>, <span class="dv">17</span>), <span class="dt">lty =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>),
                 <span class="dt">col =</span> <span class="kw">rev</span>(cols[<span class="dv">1</span>:<span class="dv">2</span>])),
    <span class="dt">text =</span> <span class="kw">list</span>(<span class="kw">c</span>(<span class="st">&quot;Intervalo de credibilidade Bayesiano&quot;</span>,
                  <span class="st">&quot;Estimativa pontual via penalização Lasso*&quot;</span>)))

<span class="kw">segplot</span>(
    pars ~<span class="st"> </span>lower +<span class="st"> </span>upper,
    <span class="dt">centers =</span> fit, <span class="dt">groups =</span> model, <span class="dt">data =</span> da.all,
    <span class="dt">horizontal =</span> <span class="ot">TRUE</span>, <span class="dt">draw =</span> <span class="ot">FALSE</span>,
    <span class="dt">key =</span> key,
    <span class="dt">pch =</span> <span class="kw">c</span>(<span class="dv">15</span>, <span class="dv">17</span>),
    <span class="dt">lwd =</span> <span class="fl">1.5</span>,
    <span class="dt">col =</span> <span class="kw">rev</span>(cols[<span class="dv">1</span>:<span class="dv">2</span>]),
    <span class="dt">gap =</span> <span class="fl">0.01</span>,
    ## scales = list(
    ##         x = list(at = 1:60,
    ##                  rot = 90,
    ##                  labels = parse(text = paste0(&quot;beta[&quot;, 1:60, &quot;]&quot;)))
    ## ),
    <span class="dt">panel =</span> function(x, y, z, ...) {
        ## panel.abline(v = 1:60, lty = 2, col = &quot;lightgray&quot;)
        <span class="kw">panel.abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">col =</span> <span class="dv">1</span>)
        ## panel.segplot(x, y, z, ...)
        cmpreg::<span class="kw">panel.groups.segplot</span>(x, y, z, ...)
    })</code></pre></div>
<div class="figure" style="text-align: center">
<img src="lista1_files/figure-html/lambdas-1.png" alt="Estimativas do parâmetro lambda pela abordagem de validação cruzada e bayesiana" width="864" />
<p class="caption">
Estimativas do parâmetro lambda pela abordagem de validação cruzada e bayesiana
</p>
</div>
<p>Na  são exibidos as estimativas do parâmetro <span class="math inline">\(\lambda\)</span> note que as estimativas pontuais foram próximas. Para os intervalos exibidos a comparação não é direta uma vez que na abordagem bayesiana os intervalos são HPD (Highest Posterior Density) e representam a credibilidade do valor e na abordagem Lasso o limite superior é dado pelo maior valor de <span class="math inline">\(\lambda\)</span> testado que confere um erro quadrático médio menor que o limite superior do erro quadrático médio do <span class="math inline">\(\lambda\)</span> ótimo.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Coeficientes Lasso
da.lasso &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(
    <span class="kw">matrix</span>(<span class="kw">coef</span>(m0lasso, <span class="dt">s =</span> <span class="st">&quot;lambda.min&quot;</span>), <span class="dt">ncol =</span> <span class="dv">3</span>,
           <span class="dt">nrow =</span> <span class="kw">length</span>(<span class="kw">coef</span>(m0lasso))))
<span class="kw">colnames</span>(da.lasso) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;fit&quot;</span>, <span class="st">&quot;lower&quot;</span>, <span class="st">&quot;upper&quot;</span>)

## Coeficientes Bayesiano com intervalo de credibilidade HPD
ambeta &lt;-<span class="st"> </span><span class="kw">select_pars</span>(amostra, <span class="dt">pars =</span> <span class="st">&quot;beta&quot;</span>)
ambeta &lt;-<span class="st"> </span><span class="kw">as.mcmc</span>(<span class="kw">do.call</span>(rbind, ambeta))
summary.beta &lt;-<span class="st"> </span><span class="kw">summary</span>(ambeta)

da.bayes &lt;-<span class="st"> </span><span class="kw">HPDinterval</span>(ambeta)
da.bayes &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="st">&quot;fit&quot;</span> =<span class="st"> </span>summary.beta$statistics[, <span class="st">&quot;Mean&quot;</span>],
                  <span class="kw">as.data.frame</span>(da.bayes))

## Junta e apresenta as estimativas via lasso e os intervalos de
## credibilidade via abordagem bayesiana
da.all &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">cbind</span>(da.bayes[-<span class="dv">1</span>, ], <span class="dt">beta =</span> <span class="dv">1</span>:<span class="dv">60</span>, <span class="dt">model =</span> <span class="st">&quot;bayes&quot;</span>),
                <span class="kw">cbind</span>(da.lasso[-<span class="dv">1</span>, ], <span class="dt">beta =</span> <span class="dv">1</span>:<span class="dv">60</span>, <span class="dt">model =</span> <span class="st">&quot;lasso&quot;</span>))
da.all &lt;-<span class="st"> </span>da.all[<span class="kw">with</span>(da.all, <span class="kw">order</span>(beta, model)), ]

key &lt;-<span class="st"> </span><span class="kw">list</span>(
    ## corner = c(0.1, 0.9),
    <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>, <span class="dt">divide =</span> <span class="dv">1</span>,
    <span class="dt">columns =</span> <span class="dv">2</span>,
    <span class="dt">lines =</span> <span class="kw">list</span>(<span class="dt">pch =</span> <span class="kw">c</span>(<span class="dv">15</span>, <span class="dv">17</span>), <span class="dt">lty =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>),
                 <span class="dt">col =</span> <span class="kw">rev</span>(cols[<span class="dv">1</span>:<span class="dv">2</span>])),
    <span class="dt">text =</span> <span class="kw">list</span>(<span class="kw">c</span>(<span class="st">&quot;Intervalo de credibilidade Bayesiano&quot;</span>,
                  <span class="st">&quot;Estimativa pontual via penalização Lasso&quot;</span>)))

<span class="kw">segplot</span>(
    beta ~<span class="st"> </span>lower +<span class="st"> </span>upper,
    <span class="dt">centers =</span> fit, <span class="dt">groups =</span> model, <span class="dt">data =</span> da.all,
    <span class="dt">horizontal =</span> <span class="ot">FALSE</span>, <span class="dt">draw =</span> <span class="ot">FALSE</span>,
    <span class="dt">key =</span> key,
    <span class="dt">pch =</span> <span class="kw">c</span>(<span class="dv">15</span>, <span class="dv">17</span>),
    <span class="dt">lwd =</span> <span class="fl">1.5</span>,
    <span class="dt">col =</span> <span class="kw">rev</span>(cols[<span class="dv">1</span>:<span class="dv">2</span>]),
    <span class="dt">gap =</span> <span class="fl">0.3</span>,
    <span class="dt">scales =</span> <span class="kw">list</span>(
            <span class="dt">x =</span> <span class="kw">list</span>(<span class="dt">at =</span> <span class="dv">1</span>:<span class="dv">60</span>,
                     <span class="dt">rot =</span> <span class="dv">90</span>,
                     <span class="dt">labels =</span> <span class="kw">parse</span>(<span class="dt">text =</span> <span class="kw">paste0</span>(<span class="st">&quot;beta[&quot;</span>, <span class="dv">1</span>:<span class="dv">60</span>, <span class="st">&quot;]&quot;</span>)))
    ),
    <span class="dt">panel =</span> function(x, y, z, ...) {
        <span class="kw">panel.abline</span>(<span class="dt">v =</span> <span class="dv">1</span>:<span class="dv">60</span>, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;lightgray&quot;</span>)
        <span class="kw">panel.abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">col =</span> <span class="dv">1</span>)
        ## panel.segplot(x, y, z, ...)
        cmpreg::<span class="kw">panel.groups.segplot</span>(x, y, z, ...)
    })</code></pre></div>
<div class="figure" style="text-align: center">
<img src="lista1_files/figure-html/coefs-1.png" alt="Coeficientes estimado pela abordagem de penalização Lasso frequentista e bayesiana" width="864" />
<p class="caption">
Coeficientes estimado pela abordagem de penalização Lasso frequentista e bayesiana
</p>
</div>
<p>Na  são exibidos os coeficientes estimados por ambas as abordagens com estimativas pontuais para a regressão sob penalização Lasso e intervalos de credibilidade para o modelo Bayesiano. Note que na abordagens Bayesiana todos os intervalos compreendem o valor 0 o que indica que nenhum coeficiente seria necessário em discordância com a regressão Lasso que indicou 14 coeficientes diferentes de zero.</p>
<p>A vantagem da abordagem Bayesiana é que há um modelo probabilístico adjacente ao método que fornece inferências mais completas, em contraste da abordagem frequentista em que o foco consiste somente em predição.</p>
<p></p>
</div>
<div id="exercicio-2" class="section level2">
<h2>Exercício 2</h2>
<blockquote>
<p><em>Neste exercício você irá implementar algumas técnicas vistas em aula para o banco de dados das faces. O objetivo aqui é conseguir criar uma função que consiga predizer para onde uma pessoa está olhando com base em uma foto. Iremos aplicar o KNN para esses dados, assim como uma regressão linear. Como não é possível usar o método dos mínimos quadrados quando o número de covariáveis é maior que o número de observações, para esta segunda etapa iremos usar o lasso.</em></p>
</blockquote>
<hr />
<blockquote>
<p><em><strong>a) </strong> Leia o banco dadosFacesAltaResolucao.txt. A primeira coluna deste banco contém a variável que indica a direção para a qual o indivíduo na imagem está olhando. As outras covariáveis contém os pixels relativos a essa imagem, que possui dimensão 64 por 64. Utilizando os comandos fornecidos, plote 5 imagens deste banco.<br />
 Divida o conjunto fornecido em treinamento (aproximadamente 60% das observações), validação (aproximadamente 20% das observações) e teste (aproximadamente 20% das observações). Utilizaremos o conjunto de treinamento e validação para ajustar os modelos. O conjunto de teste será utilizado para testar sua performance.</em></p>
</blockquote>
<p>A leitura do conjunto de dados para manipulação no software R é realizada conforme código abaixo:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Leitura dos dados
dados &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;./data/dadosFacesAltaResolucao.txt&quot;</span>,
                  <span class="dt">header =</span> <span class="ot">TRUE</span>, <span class="dt">sep =</span> <span class="st">&quot; &quot;</span>)

## Verificando
## str(dados)
<span class="kw">dim</span>(dados)</code></pre></div>
<pre><code>## [1]  698 4097</code></pre>
<p>Na  são exibidas as seis primeiras imagens do conjunto da dados para ilustrar como o conjunto é constituído.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##----------------------------------------------------------------------
## Plotando as imagens
imagens &lt;-<span class="st"> </span><span class="kw">lapply</span>(<span class="kw">as.data.frame</span>(<span class="kw">t</span>(dados[, -<span class="dv">1</span>])),
                  function(x) <span class="kw">matrix</span>(x, <span class="dt">ncol =</span> <span class="dv">64</span>))
xys &lt;-<span class="st"> </span><span class="kw">lapply</span>(<span class="dv">1</span>:<span class="dv">6</span>, function(x) {
    main &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;Figura&quot;</span>, x, <span class="st">&quot;(Direção &quot;</span>, dados$y[x], <span class="st">&quot;)&quot;</span>)
    xy &lt;-<span class="st"> </span><span class="kw">levelplot</span>(imagens[[x]],
                    <span class="dt">sub =</span> main,
                    <span class="dt">xlab =</span> <span class="st">&quot;&quot;</span>,
                    <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>,
                    <span class="dt">scales =</span> <span class="kw">list</span>(<span class="dt">draw =</span> <span class="ot">FALSE</span>),
                    <span class="dt">par.settings =</span> <span class="kw">list</span>(
                        <span class="dt">layout.heights =</span>
                            <span class="kw">list</span>(<span class="dt">top.padding =</span> <span class="dv">0</span>,
                                 <span class="dt">bottom.padding =</span> <span class="dv">1</span>,
                                 <span class="dt">key.sub.padding =</span> <span class="dv">0</span>
                                 ),
                        <span class="dt">layout.widths =</span>
                            <span class="kw">list</span>(<span class="dt">left.padding =</span> <span class="dv">0</span>,
                                 <span class="dt">right.padding =</span> <span class="dv">0</span>)))
})

gridExtra::<span class="kw">marrangeGrob</span>(xys, <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">ncol =</span> <span class="dv">3</span>, <span class="dt">top =</span> <span class="ot">NA</span>)</code></pre></div>
<div class="figure" style="text-align: center">
<img src="lista1_files/figure-html/images-1.png" alt="Seis primeiras imagens representadas no conjunto de dados" width="864" />
<p class="caption">
Seis primeiras imagens representadas no conjunto de dados
</p>
</div>
<p>Para a partição do conjunto de dados foi implementada uma rotina que realiza a divisão da base conforme proporções informadas, a implementação pode ser vista no <a href="https://jreduardo.github.io/est171-ml/">complemento online</a> do trabalho.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Particionando o conjunto de dados
dasplit &lt;-<span class="st"> </span><span class="kw">mysplit</span>(dados, <span class="dt">percent =</span> <span class="kw">c</span>(<span class="fl">0.6</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>),
                   <span class="dt">seed =</span> <span class="dv">1994</span>)

## Número de observações em cada partição
<span class="kw">sapply</span>(dasplit, dim)</code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]  418  140  140
## [2,] 4097 4097 4097</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Atribuindo as partições em objetos de nome sujestivo
da.train &lt;-<span class="st"> </span>dasplit[[<span class="dv">1</span>]]
da.valid &lt;-<span class="st"> </span>dasplit[[<span class="dv">2</span>]]
da.teste &lt;-<span class="st"> </span>dasplit[[<span class="dv">3</span>]]</code></pre></div>
<hr />
<blockquote>
<p><em><strong>b) </strong> Qual o número de observações? Qual o número de covariáveis? O que representa cada covariável?</em></p>
</blockquote>
<p>Neste conjunto de dados são 698 observações, que representam imagens, faces humanas, com a indicação da direção para a qual a face está virada e da intensidade da coloração em cada pixel. A imagem tem resolução 64px <span class="math inline">\(x\)</span> 64px, portanto têm-se 4096 covariáveis que representam a intensidade de coloração em cada pixel.</p>
<hr />
<blockquote>
<p><em><strong>c) </strong> Para cada observação do conjunto de teste, calcule o estimador da função de regressão <span class="math inline">\(r()\)</span> dado pelo método dos <span class="math inline">\(k\)</span> vizinhos mais próximos com <span class="math inline">\(k = 5\)</span>. Você pode usar as funções vistas em aula.</em></p>
</blockquote>
<p>Para esta tarefa utilizou-se o pacote FNN (Fast Nearest Neighbor) do R. Na  são exibidos as predição provenientes da aplicação do método KNN com cinco vizinhos. Vale destacar que os valores exibidos na figura são predições da base de teste utilizando para treinamento o conjunto de treino e validação.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(FNN)
train &lt;-<span class="st"> </span><span class="kw">rbind</span>(da.train, da.valid)
knn.model &lt;-<span class="st"> </span><span class="kw">knn.reg</span>(<span class="dt">train =</span> train, <span class="dt">test =</span> da.teste,
                     <span class="dt">y =</span> train[, <span class="st">&quot;y&quot;</span>], <span class="dt">k =</span> <span class="dv">5</span>)

xy1 &lt;-<span class="st"> </span><span class="kw">xyplot</span>(knn.model$pred ~<span class="st"> </span><span class="kw">seq_along</span>(knn.model$pred),
              <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">&quot;p&quot;</span>, <span class="st">&quot;g&quot;</span>),
              <span class="dt">xlab =</span> <span class="st">&quot;Índice da imagem (no conjunto de teste)&quot;</span>,
              <span class="dt">ylab =</span> <span class="st">&quot;Valor predito para a direção&quot;</span>)

xy2 &lt;-<span class="st"> </span><span class="kw">xyplot</span>(da.teste[, <span class="dv">1</span>] ~<span class="st"> </span>knn.model$pred,
              <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">&quot;p&quot;</span>, <span class="st">&quot;g&quot;</span>),
              <span class="dt">xlab =</span> <span class="st">&quot;Valor predito&quot;</span>,
              <span class="dt">yla =</span> <span class="st">&quot;Valor observado&quot;</span>,
              <span class="dt">panel =</span> function(x, y, ...) {
                  <span class="kw">panel.xyplot</span>(x, y, ...)
                  <span class="kw">panel.abline</span>(<span class="dv">0</span>, <span class="dv">1</span>)
              })

<span class="kw">print</span>(xy1, <span class="dt">split =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dt">more =</span> <span class="ot">TRUE</span>)
<span class="kw">print</span>(xy2, <span class="dt">split =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dt">more =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center">
<img src="lista1_files/figure-html/fitknn-1.png" alt="Valores preditos pelo método KNN com 5 vizinhos. Valor preditos na ordem do conjunto de teste (esquerda) e preditos versus observados (direita)" width="960" />
<p class="caption">
Valores preditos pelo método KNN com 5 vizinhos. Valor preditos na ordem do conjunto de teste (esquerda) e preditos versus observados (direita)
</p>
</div>
<hr />
<blockquote>
<p><em><strong>d) </strong> Utilize validação cruzada (data splitting) para escolher o melhor <span class="math inline">\(k\)</span>. Plote <span class="math inline">\(k\)</span> vs Risco estimado.</em></p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">kseq &lt;-<span class="st"> </span><span class="dv">1</span>:(<span class="kw">nrow</span>(da.train))
resultsknn &lt;-<span class="st"> </span><span class="kw">lapply</span>(kseq, function(k) {
    model &lt;-<span class="st"> </span><span class="kw">knn.reg</span>(<span class="dt">train =</span> da.train, <span class="dt">test =</span> da.valid,
                     <span class="dt">y =</span> da.train[, <span class="st">&quot;y&quot;</span>], <span class="dt">k =</span> k)
    pred &lt;-<span class="st"> </span>model$pred
    eqs &lt;-<span class="st"> </span>(da.valid[, <span class="st">&quot;y&quot;</span>] -<span class="st"> </span>pred)^<span class="dv">2</span>
    <span class="kw">list</span>(<span class="dt">eqs =</span> eqs, <span class="dt">pred =</span> pred)
})</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Calcula os erros quadráticos médios
eqs.mean &lt;-<span class="st"> </span><span class="kw">sapply</span>(resultsknn, function(x) <span class="kw">mean</span>(x[[<span class="st">&quot;eqs&quot;</span>]]))
eqs.median &lt;-<span class="st"> </span><span class="kw">sapply</span>(resultsknn, function(x) <span class="kw">median</span>(x[[<span class="st">&quot;eqs&quot;</span>]]))

## Organiza em data.frame
medidas &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">k =</span> kseq, <span class="dt">mean =</span> eqs.mean, <span class="dt">median =</span> eqs.median)
da &lt;-<span class="st"> </span>reshape2::<span class="kw">melt</span>(medidas, <span class="dt">id.vars =</span> <span class="st">&quot;k&quot;</span>)

## Exibe graficamente
fl &lt;-<span class="st"> </span><span class="kw">expression</span>(<span class="kw">E</span>(<span class="kw">EQM</span>(model[p])),
                 <span class="kw">Md</span>(<span class="kw">EQM</span>(model[p])))
xy1 &lt;-<span class="st"> </span><span class="kw">xyplot</span>(<span class="kw">log</span>(value) ~<span class="st"> </span>k |<span class="st"> </span>variable,
              <span class="dt">type =</span> <span class="st">&quot;S&quot;</span>,
              <span class="dt">data =</span> da,
              <span class="dt">ylab =</span> <span class="kw">expression</span>(<span class="kw">log</span>(<span class="kw">hat</span>(R))),
              <span class="dt">as.table =</span> <span class="ot">TRUE</span>,
              <span class="dt">layout =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="dv">1</span>),
              <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>,
              <span class="dt">strip =</span> <span class="kw">strip.custom</span>(<span class="dt">factor.levels =</span> fl),
              <span class="dt">panel =</span> function(x, y, subscripts, ...) {
                  <span class="kw">panel.grid</span>()
                  <span class="kw">panel.xyplot</span>(x, y, ...)
                  <span class="kw">panel.abline</span>(<span class="dt">h =</span> <span class="kw">min</span>(y, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),
                               <span class="dt">v =</span> <span class="kw">which.min</span>(y),
                               <span class="dt">lty =</span> <span class="dv">2</span>)
              })

## Exibe apenas os 8 k&#39;s mais próximos (acima e abaixo) do mínimo
medidas.min &lt;-<span class="st"> </span><span class="kw">sapply</span>(medidas[, -<span class="dv">1</span>], which.min)
index &lt;-<span class="st"> </span><span class="kw">c</span>(-<span class="dv">8</span>:<span class="dv">8</span>) +<span class="st"> </span><span class="kw">which.min</span>(eqs.mean)
medidas &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">k =</span> kseq[index],
                      <span class="dt">mean =</span> eqs.mean[index],
                      <span class="dt">median =</span> eqs.median[index])
da &lt;-<span class="st"> </span>reshape2::<span class="kw">melt</span>(medidas, <span class="dt">id.vars =</span> <span class="st">&quot;k&quot;</span>)

xy2 &lt;-<span class="st"> </span><span class="kw">xyplot</span>(<span class="kw">log</span>(value) ~<span class="st"> </span>k |<span class="st"> </span>variable,
              <span class="dt">type =</span> <span class="st">&quot;S&quot;</span>,
              <span class="dt">data =</span> da,
              <span class="dt">ylab =</span> <span class="kw">expression</span>(<span class="kw">log</span>(<span class="kw">hat</span>(R))),
              <span class="dt">as.table =</span> <span class="ot">TRUE</span>,
              <span class="dt">layout =</span> <span class="kw">c</span>(<span class="ot">NA</span>, <span class="dv">1</span>),
              <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>,
              <span class="dt">strip =</span> <span class="kw">strip.custom</span>(<span class="dt">factor.levels =</span> fl),
              <span class="dt">panel =</span> function(x, y, subscripts, ...) {
                  <span class="kw">panel.grid</span>()
                  <span class="kw">panel.xyplot</span>(x, y, ...)
                  <span class="kw">panel.abline</span>(<span class="dt">h =</span> <span class="kw">min</span>(y, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),
                               <span class="dt">v =</span> <span class="kw">which.min</span>(y),
                               <span class="dt">lty =</span> <span class="dv">2</span>)
              })

<span class="kw">print</span>(xy1, <span class="dt">split =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>), <span class="dt">more =</span> <span class="ot">TRUE</span>)
<span class="kw">print</span>(xy2, <span class="dt">split =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>), <span class="dt">more =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center">
<img src="lista1_files/figure-html/plotknncv-1.png" alt="Erros quadráticos médios e medianos na escala logarítimica (linha pontilhada representa a indicação do melhor modelo). Para todos o vizinhos (acima) e apenas para os k's próximos do ótimo (abaixo)." width="864" />
<p class="caption">
Erros quadráticos médios e medianos na escala logarítimica (linha pontilhada representa a indicação do melhor modelo). Para todos o vizinhos (acima) e apenas para os k’s próximos do ótimo (abaixo).
</p>
</div>
<hr />
<blockquote>
<p><em><strong>e) </strong> Utilizando o conjunto de teste, estime o risco do KNN para o melhor <span class="math inline">\(k\)</span>. Plote os valores preditos versus os valores observados para o conjunto de teste. Inclua a reta identidade.</em></p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Indicação do melhor algoritmo preditivo
index &lt;-<span class="st"> </span><span class="kw">which.min</span>(eqms.median)

## Calibra o método com base no melhor k
train &lt;-<span class="st"> </span><span class="kw">rbind</span>(da.train, da.valid)
knn.model &lt;-<span class="st"> </span><span class="kw">knn.reg</span>(<span class="dt">train =</span> train, <span class="dt">test =</span> da.teste,
                     <span class="dt">y =</span> train[, <span class="st">&quot;y&quot;</span>], <span class="dt">k =</span> kseq[index])

##
xy1 &lt;-<span class="st"> </span><span class="kw">xyplot</span>(da.teste[, <span class="dv">1</span>] ~<span class="st"> </span>knn.model$pred,
              <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">&quot;p&quot;</span>, <span class="st">&quot;g&quot;</span>),
              <span class="dt">panel =</span> function(x, y, ...) {
                  <span class="kw">panel.xyplot</span>(x, y, ...)
                  <span class="kw">panel.abline</span>(<span class="dv">0</span>, <span class="dv">1</span>)
              })

xy2 &lt;-<span class="st"> </span><span class="kw">xyplot</span>(da.teste[, <span class="dv">1</span>] -<span class="st"> </span>knn.model$pred ~<span class="st"> </span><span class="kw">seq_along</span>(da.teste[, <span class="dv">1</span>]),
              <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">&quot;p&quot;</span>, <span class="st">&quot;g&quot;</span>, <span class="st">&quot;smooth&quot;</span>),
              <span class="dt">panel =</span> function(x, y, ...) {
                  <span class="kw">panel.xyplot</span>(x, y, ...)
                  <span class="kw">panel.abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> cols[<span class="dv">2</span>])
              })

<span class="kw">print</span>(xy1, <span class="dt">split =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dt">more =</span> <span class="ot">TRUE</span>)
<span class="kw">print</span>(xy2, <span class="dt">split =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dt">more =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center">
<img src="lista1_files/figure-html/predknn-1.png" alt="Valores preditos pelo método KNN com 10 vizinhos. Preditos versus observados (esquerda) e desvios (direita)." width="960" />
<p class="caption">
Valores preditos pelo método KNN com 10 vizinhos. Preditos versus observados (esquerda) e desvios (direita).
</p>
</div>
<hr />
<blockquote>
<p><em><strong>f) </strong> Ajuste uma regressão linear para os dados usando o conjunto de treinamento mais o de validação via lasso (lembre-se que a função que ajusta o lasso no R já faz validação cruzada automaticamente: ao contrário do KNN, neste caso não é necessário separar os dados em treinamento e validação). Qual o lambda escolhido? Plote <span class="math inline">\(\lambda\)</span> vs Risco estimado.</em></p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##----------------------------------------------------------------------
## Regressão com penalização do tipo Lasso
<span class="kw">library</span>(glmnet)
## Validação leave-one-out (demorado!)
train &lt;-<span class="st"> </span><span class="kw">rbind</span>(da.train, da.valid)
lasso.model &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(<span class="dt">x =</span> <span class="kw">as.matrix</span>(train[, -<span class="dv">1</span>]), <span class="dt">y =</span> train[, <span class="st">&quot;y&quot;</span>],
                         <span class="dt">family =</span> <span class="st">&quot;gaussian&quot;</span>, <span class="dt">alpha =</span> <span class="dv">1</span>,
                         <span class="dt">nfolds =</span> <span class="kw">nrow</span>(train), <span class="dt">grouped =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>Para ajuste da regressão linear sob penalização do tipo Lasso utilizou-se a validação cruzada do tipo leave-one-out para estudo do parâmetro <span class="math inline">\(\lambda\)</span> de penalização. Os resultados da validação cruzada são exibidos na  onde têm-se os erros quadráticos médios em função dos <span class="math inline">\(\lambda\)</span>’s na escala logarítmica. O <span class="math inline">\(\lambda\)</span> que minimiza o erro quadrático médio é 0.339318 e o maior <span class="math inline">\(\lambda\)</span>, cujo erro quadrático médio é menor que o limite superior do erro sob o <span class="math inline">\(\lambda\)</span> ótimo é 0.4699169.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(lasso.model)</code></pre></div>
<div class="figure" style="text-align: center">
<img src="lista1_files/figure-html/plotlassofaces-1.png" alt="Lambdas versus erros quadráticos médios" width="864" />
<p class="caption">
Lambdas versus erros quadráticos médios
</p>
</div>
<hr />
<blockquote>
<p><em><strong>g) </strong> Utilizando o conjunto de teste, estime o risco do lasso para o melhor <span class="math inline">\(\lambda\)</span>. Plote os valores preditos versus os valores observados para o conjunto de teste. Inclua a reta identidade.</em></p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred.lasso &lt;-<span class="st"> </span><span class="kw">predict</span>(lasso.model, <span class="dt">newx =</span> <span class="kw">as.matrix</span>(da.teste[, -<span class="dv">1</span>]),
                      <span class="dt">s =</span> <span class="st">&quot;lambda.min&quot;</span>)

xy1 &lt;-<span class="st"> </span><span class="kw">xyplot</span>(da.teste[, <span class="dv">1</span>] ~<span class="st"> </span>pred.lasso,
              <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">&quot;p&quot;</span>, <span class="st">&quot;g&quot;</span>),
              <span class="dt">xlab =</span> <span class="st">&quot;Valores preditos&quot;</span>,
              <span class="dt">ylab =</span> <span class="st">&quot;Valores observados&quot;</span>,
              <span class="dt">panel =</span> function(x, y, ...) {
                  <span class="kw">panel.xyplot</span>(x, y, ...)
                  <span class="kw">panel.abline</span>(<span class="dv">0</span>, <span class="dv">1</span>)
              })

xy2 &lt;-<span class="st"> </span><span class="kw">xyplot</span>(da.teste[, <span class="dv">1</span>] -<span class="st"> </span>pred.lasso ~<span class="st"> </span><span class="kw">seq_along</span>(da.teste[, <span class="dv">1</span>]),
              <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">&quot;p&quot;</span>, <span class="st">&quot;g&quot;</span>, <span class="st">&quot;smooth&quot;</span>),
              <span class="dt">xlab =</span> <span class="st">&quot;Indice da imagem (no conjunto de teste)&quot;</span>,
              <span class="dt">ylab =</span> <span class="st">&quot;Desvios (observado - predito)&quot;</span>,
              <span class="dt">panel =</span> function(x, y, ...) {
                  <span class="kw">panel.xyplot</span>(x, y, ...)
                  <span class="kw">panel.abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> cols[<span class="dv">2</span>])
              })

<span class="kw">print</span>(xy1, <span class="dt">split =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dt">more =</span> <span class="ot">TRUE</span>)
<span class="kw">print</span>(xy2, <span class="dt">split =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dt">more =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center">
<img src="lista1_files/figure-html/predlasso-1.png" alt="Valores preditos pelo método Lasso. Preditos versus observados (esquerda) e desvios (direita)." width="960" />
<p class="caption">
Valores preditos pelo método Lasso. Preditos versus observados (esquerda) e desvios (direita).
</p>
</div>
<hr />
<blockquote>
<p><em><strong>h) </strong> Quantos coeficientes foram estimados como sendo zero?</em></p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ncoef &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">as.matrix</span>(<span class="kw">coef</span>(lasso.model, <span class="dt">s =</span> <span class="st">&quot;lambda.min&quot;</span>)) !=<span class="st"> </span><span class="dv">0</span>)</code></pre></div>
<p>Via penalização Lasso com <span class="math inline">\(\lambda\)</span>= 0.339318 foram apenas 120 coeficientes de 4096, cujo valor não foi zerado.</p>
<hr />
<blockquote>
<p><em><strong>i) </strong> Qual modelo teve melhores resultados: regressão linear via lasso ou KNN?</em></p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred.knn &lt;-<span class="st"> </span><span class="kw">knn.reg</span>(<span class="dt">train =</span> train, <span class="dt">test =</span> da.teste,
                     <span class="dt">y =</span> train[, <span class="st">&quot;y&quot;</span>], <span class="dt">k =</span> kseq[index])$pred
eqm.knn &lt;-<span class="st"> </span>(da.teste[, <span class="dv">1</span>] -<span class="st"> </span>pred.knn)^<span class="dv">2</span>
eqm.lasso &lt;-<span class="st"> </span>(da.teste[, <span class="dv">1</span>] -<span class="st"> </span>pred.lasso)^<span class="dv">2</span>

da &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">eqm =</span> <span class="kw">c</span>(eqm.knn, eqm.lasso),
                 <span class="dt">model =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;knn&quot;</span>, <span class="st">&quot;lasso&quot;</span>),
                             <span class="dt">each =</span> <span class="kw">nrow</span>(da.teste)))

<span class="kw">xyplot</span>(eqm ~<span class="st"> </span>model,
       <span class="dt">data =</span> da,
       <span class="dt">ylab =</span> <span class="kw">expression</span>(Erro~Quadrático),
       <span class="dt">xlab =</span> <span class="st">&quot;Método&quot;</span>,
       <span class="dt">scales =</span> <span class="kw">list</span>(<span class="dt">y =</span> <span class="kw">list</span>(<span class="dt">log =</span> <span class="ot">TRUE</span>)),
       <span class="dt">panel =</span> function(x, y, ...) {
           <span class="kw">panel.grid</span>(<span class="dt">h =</span> -<span class="dv">1</span>, <span class="dt">v =</span> <span class="dv">0</span>)
           <span class="kw">panel.xyplot</span>(<span class="dt">x =</span> <span class="kw">as.integer</span>(x) -<span class="st"> </span><span class="fl">0.05</span>, <span class="dt">y =</span> y,
                        <span class="dt">col =</span> <span class="st">&quot;gray60&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.7</span>, <span class="dt">cex =</span> <span class="fl">0.8</span>,
                        <span class="dt">jitter.x =</span> <span class="ot">TRUE</span>, <span class="dt">factor =</span> <span class="fl">0.1</span>, ...)
           <span class="kw">panel.bwplot</span>(<span class="dt">x =</span> <span class="kw">as.integer</span>(x) +<span class="st"> </span><span class="fl">0.05</span>, <span class="dt">y =</span> y,
                        <span class="dt">horizontal =</span> <span class="ot">FALSE</span>, <span class="dt">box.width =</span> <span class="fl">0.1</span>)
           means &lt;-<span class="st"> </span><span class="kw">tapply</span>(y, x, mean)
           <span class="kw">panel.points</span>(<span class="dt">y =</span> means, <span class="dt">x =</span> <span class="kw">unique</span>(<span class="kw">as.integer</span>(x)) +<span class="st"> </span><span class="fl">0.05</span>,
                        <span class="dt">pch =</span> <span class="dv">15</span>)
       })</code></pre></div>
<div class="figure" style="text-align: center">
<img src="lista1_files/figure-html/compare-1.png" alt="Comparação dos métodos preditivos KNN e regressão Lasso via erros quadráticos" width="864" />
<p class="caption">
Comparação dos métodos preditivos KNN e regressão Lasso via erros quadráticos
</p>
</div>
<p>Ambos os métodos são meramente preditivos, ou seja, são algoritmos numéricos em que não se faz inferências a não ser a predição, pois não assume-se modelo, verossimilhança, etc. Portanto, para a comparação dos métodos utilizou-se o erro quadrático de predição no conjunto de teste. Os resultados para comparação são exibidos na . Note que os erros são, em média, menores para o KNN favorecendo esse método em detrimento da regressão Lasso. Outra característica observada na figura que favorece o KNN é a dispersão dos erros, que é menor para o KNN. Isso mostra que o método KNN, aplicado a esse conjunto de dados, proporcionou melhores resultados que o método de regressão sob penalização Lasso.</p>
</div>
<div id="material-suplementar" class="section level2">
<h2>Material suplementar</h2>
<p>Todos os códigos (para manipulação, ajustes e gráficos) exibidos neste trabalho estão disponíveis no endereço <a href="https://jreduardo.github.io/est171-ml/" class="uri">https://jreduardo.github.io/est171-ml/</a>.</p>
</div>

<br>
<hr>
<center>© Copyright 2016 Ribeiro Jr., E. E.</center>
<br>

<div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname = 'eerj-website';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
  </script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>



</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
