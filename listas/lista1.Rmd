---
title: Aprendizado de Máquina
subtitle: UFMG EST171 - 1ª Lista de exercícios
author: Eduardo E. R. Junior \& Matheus H. Sales
date: 12 de setembro de 2016
output:
  pdf_document:
    keep_tex: true
    includes:
      in_header: ../_preambulo.tex
---

```{r setup, include = FALSE}

source("../_setup.R")
opts_chunk$set(
    cache = FALSE,
    echo = TRUE,
    fig.pos = "H")
cols <- trellis.par.get("superpose.line")$col

library(rjags)
library(glmnet)
library(FNN)

```

```{r functions}


## Para construir as matrizes do modelo (exercício 1)
buildX <- function(x, p) {
    X <- matrix(1, nrow = length(x))
    v <- 2 * pi * x
    for (p in 1:p) {
        m <- cbind(xs = sin(v * p), xc = cos(v * p))
        colnames(m) = paste0(colnames(m), p)
        X <- cbind(X, m)
    }
    return(X)
}

## Para seleção de amostra MCMC de apenas alguns parâmetros
select_pars <- function(sample, pars) {
    if (!is.mcmc.list(sample)) {
        sample <- as.mcmc.list(sample)
    }
    out <- lapply(sample, function(x) {
        sel <- gsub("\\[[0-9]+\\]", repl = "", colnames(x))
        x[, sel %in% pars]
    })
    return(as.mcmc(out))
}

## Para partição de uma base de dados em dados de treinamento,
## validação, teste, etc.
mysplit <- function(data, percent = NA, nfolds = NA,
                    nobs = NA, seed = NULL) {
    if (sum(is.na(c(percent, nfolds, nobs))) != 2) {
        stop("Utilize um e apenas um dos argumentos")
    }
    n <- nrow(data)
    if (!sum(is.na(percent))) {
        if (sum(percent) != 1) {
            stop("Os percentuais em cada dobra devem somar 1!")
        }
        p <- percent
        folds <- n * p
    }
    if (!is.na(nfolds)) {
        if (nfolds > n) {
            stop(paste0("O número de dobras não deve exceder o ",
                       "tamanho da amostra (n=", n, ")!"))
        }
        p <- rep(1/nfolds, nfolds)
        folds <- n * p
    }
    if (!sum(is.na(nobs))) {
        if (sum(nobs) != n) {
            stop(paste0("O número de observações em cada dobra deve ",
                       "somar ", n, "!"))
        }
        folds <- nobs
    }
    if (!is.null(seed)) {
        set.seed(seed)
    }
    folds <- round(folds)
    while (sum(folds) != n) {
        g <- sample(1:length(folds), 1)
        if (sum(folds) < n) {
            folds[g] <- folds[g] + 1
        } else {
            folds[g] <- folds[g] - 1
        }
    }
    out <- vector("list", length = length(folds))
    for (i in 1:length(folds)) {
        index <- sample(nrow(data), size = folds[i])
        out[[i]] <- data[index, ]
        data <- data[-index, ]
    }
    return(out)
}

```

## Exercício 1 ##

> Baixe os dados worldDevelopmentIndicators.csv, que contém os dados do
  PIB per capita (X) e a expectativa de vida (Y) de diversos países. O
  objetivo é criar preditores de Y com base em X. Em aula vimos como
  isso pode ser feito através de polinômios. Aqui, faremos isso via
  expansões de Fourier.

Como são dados bidimensionais uma representação gráfica é realizada na
\autoref{fig:descritiva}. Note que não há um padrão cíclico aparente que
justifique a utilização de expansões via séries de Fourier, porém essas
serão utilizadas para ilustração das técnicas apresentadas na disciplina.

```{r descritiva, fig.cap = "Dispersão do dados"}

dados <- read.table("./data/worldDevelopmentIndicators.csv",
                     header = TRUE, sep = ",", quote = "\"",
                     stringsAsFactors = FALSE)
names(dados) <- c("country", "y", "x")

xyplot(y ~ x, data = dados,
       type = c("g", "p", "smooth"),
       xlab = "PIB per capita",
       ylab = "Expectativa de vida")

```

***
> _**a)** Normalize a covariável de modo que $x \in (0, 1)$. Para isso,
  faça $x = \frac{x-xmin}{xmax-xmin}$, onde $xmin$ e $xmax$ são os
  valores mínimo e máximo de $x$ segundo a amostra usada._

Após realizada a padronização da variável conforme indicação do exercício,
apresenta-se seu comportamento via densidade estimada na
\autoref{fig:densx}, note a forte assimetria da variável com quase 75\%
dos seus valores abaixo de 0.1.

```{r densx, fig.cap = "Densidade estimada do PIB per capita padronizado"}

dados <- transform(dados, x = (x - min(x)) / (max(x) - min(x)))
## summary(dados$x)
densityplot(~x, data = dados, grid = TRUE)

```

***
> _**b)** Usando o método dos mínimos quadrados e a validação cruzada do
  tipo leave-one-out, estime o erro quadrático médio das regressões
  $$g(x) = \sum_{i=1}^p \beta_{si} sin(2 \pi i x) + \beta_{ci} cos(2 \pi
  i x), \qquad \text{para } p = 1, 2, \ldots, 30$$_

Para o ajuste e estimação do erro quadrático médio de tais regressões
utilizou-se o software R com a rotina descrita abaixo:

 1. Ajuste dos modelos, tendo os modelos armazenados outras medidas de
    qualidade podem ser extraídas.
```{r fitfourier, echo = TRUE}

X <- cbind()
models <- vector("list", 30)
v <- 2 * pi * dados$x

## Ajuste todos os modelos
for (p in 1:30) {
    m <- cbind(xs = sin(v * p), xc = cos(v * p))
    colnames(m) = paste0(colnames(m), p)
    X <- cbind(X, m)
    models[[p]] <- lm(y ~ X, data = dados)
}

```

 2. Calcula o erro quadrático para cada observação retirada do ajuste e
    posteriormente predita pelos $p$ modelos. Mantém apenas os erros
    quadráticos para avaliação de seu comportamento, uma vez que
    resumos, como a média podem ser obtidos facilmente. Os valores
    preditos de cada observação também são armazenados.
```{r eqsfourier, echo = TRUE, cache = TRUE}

## Calcula o erro quadrático de cada observação para cada modelo via
## cross-validation leave-one-out
results <- lapply(models, function(modelo) {
    n <- nrow(modelo$model)
    eqs <- vector("numeric", length = n)
    pred <- vector("numeric", length = n)
    for (i in 1:n) {
        ## obs <- as.data.frame(modelo$model[i, ])
        ## mod <- update(modelo, data = modelo$model[-i, ])
        ## pred[i] <- predict(mod, newdata = obs)
        obs <- modelo$model$y[i]
        mod <- with(modelo$model,
                    .lm.fit(x = cbind(1, X[-i, ]), y = y[-i]))
        pred[i] <- cbind(1, modelo$model$X)[i, ] %*% mod$coefficients
        eqs[i] <- (obs - pred[i])^2
    }
    list(eqs = eqs, pred = pred)
})

## Extraindo os erros quadráticos médios
eqms.mean <- sapply(results, function(x) mean(x[["eqs"]]))

```
Caso prefiro funções prontas, existe um pacote no R, `cvTools` que
realiza a validação cruzada do tipo leave-one-out, além de outras
estratégias.
```{r cvTools, echo = TRUE, eval = FALSE}

##-------------------------------------------
## Pra quem gosta de pacotes ...
library(cvTools)
teste <- sapply(models, function(x) cvLm(x, cost = mspe, K = 211)$cv)
teste == eqms.mean
##-------------------------------------------

```

***
> _**c)** Plote o gráfico do risco estimado vs $p$. Qual o valor de $p$
  escolhido? Denotaremos ele por $p_{esc}$_

Primeiramente para a escolha do $p$ decidiu-se por avaliar o
comportamento dos erros em cada modelo ajustado. Essa avaliação é
exibida na \autoref{fig:boxplotseqs}, onde apresenta-se os erros
quadráticos para cada observação em cada modelo na escala logarítmica
com a indicação da média, mediana e quartis. Note que o comportamento
dos erros é bastante assimétrico, manifestando essa assimetria também na
escala logarítmica. Além da assimetria muitos pontos discrepantes são
observados, principalmente nos modelos mais complexos ($p > 12$). Devido
a isso decidiu-se por apresentar, além do erro quadrático médio, erro
quadrático mediano, pela mediana ser uma medida resumo menos sensível a
dados extremos.

```{r boxplotseqs, fig.cap="Distribuição empírica dos logarítmos dos erros quadráticos médios para cada um dos p modelos"}

eqs <- do.call(cbind, lapply(results, function(x) x[["eqs"]]))
colnames(eqs) <- 1:30
eqs <- stack(as.data.frame(eqs))
eqs$ind <- as.integer(as.character(eqs$ind))

## Exibição gráfica
##  -- Legenda
key <- list(
    corner = c(0.05, 0.9),
    points = list(pch = 15),
    text = list(expression(Média~dos~log(eqs)))
)
##  -- Gráfico
xyplot(log(values) ~ factor(ind),
       data = eqs,
       key = key,
       xlab = "p",
       ylab = expression(log(Erro~Quadrático)),
       panel = function(x, y, subscripts, ...) {
           panel.grid(h = -1, v = 0)
           panel.xyplot(x = as.integer(x) - 0.1, y = y,
                        col = "gray60", alpha = 0.7, cex = 0.8, ...)
           panel.bwplot(x = as.integer(x) + 0.1, y = y,
                        horizontal = FALSE, box.width = 0.4)
           means <- tapply(y, x, mean)
           panel.points(y = means, x = unique(as.integer(x)) + 0.1,
                        pch = 15)
       })

```

```{r measuresfourier, fig.height=4, fig.width=9, fig.cap="Medidas de qualidade de predição na escala logarítimica (linha pontilhada representa a indicação do melhor modelo)"}

## Medidas de qualidade de predição/ajuste
eqms.median <- sapply(results, function(x) median(x[["eqs"]]))
aics <- sapply(models, AIC)

## Agrupando as medidas
medidas <- data.frame(p = 1:30,
                      mean = eqms.mean,
                      median = eqms.median,
                      aics = aics)

## Indicação dos melhores modelos
medidas.min <- sapply(medidas[, -1], which.min)

## Representação gráfica
da <- reshape2::melt(medidas, id.vars = "p")
fl <- expression(E(EQM(model[p])),
                 Md(EQM(model[p])),
                 AIC(model[p]))
xyplot(log(value) ~ p | variable,
       type = "S",
       data = da,
       ylab = expression(log(hat(R))),
       as.table = TRUE,
       layout = c(NA, 1),
       scales = "free",
       strip = strip.custom(factor.levels = fl),
       panel = function(x, y, subscripts, ...) {
           panel.grid()
           panel.xyplot(x, y, ...)
           panel.abline(h = min(y, na.rm = TRUE),
                        v = which.min(y),
                        lty = 2)
       })

```

Na \autoref{fig:measuresfourier} são apresentadas as medidas de
qualidade de predição e ajuste para todos os $p$ modelos. São
apresentados os erros quadráticos médios e medianos e também o AIC
(Critério de Informação de Akaike) como uma medida mais estatística que
mensura a parcimônia do modelo. As três medidas indicaram diferentes
modelos sendo p = `r paste(medidas.min, collapse=", ")` para as medidas
erro quadrático médio, erro quadrático mediano e AIC,
respectivamente. Desta forma, nas análises subsequentes serão
apresentados os resultados para os modelos com p =
`r paste(medidas.min[-3], collapse=", ")`.

***
> _**d)** Plote os das curvas ajustadas para p = 1 ; p = $p_{esc}$ e p =
  30 sob o gráfico de dispersão de X por Y.  Qual curva parece mais
  razoável? Use um grid de valores entre 0 e 1 para isso. Como estes
  ajustes se comparam com o visto em aula via polinômios? Discuta_.

```{r curvefourier, fig.width=10, fig.height=5, fig.cap="Curvas ajustadas. Conjuntamente no intervalo dos dados (esquerda) e individuais no interrvalo de predição (direita)."}

## Os modelos que serão comparados
index <- c(1, medidas.min[1:2], 30)

## Curva dos modelos
lista <- models[index]
pred <- lapply(lista, function(modelo) {
    x = seq(0, 1, length.out = 50)
    betas <- coef(modelo)
    X <- buildX(x = x, p = (length(betas) - 1)/2)
    out <- cbind(x, X %*% betas)
    colnames(out) <- c("x", "yhat")
    out
})

names(pred) <- index
da <- plyr::ldply(pred, .id = "model")

leg <- parse(text = paste0("model[", index, "]"))
key <- list(
    space = "top",
    column = 2,
    lines = list(col = cols[seq_along(index)], lty = 1),
    text = list(leg)
)

xy1 <- xyplot(y ~ x, data = dados,
              type = c("g", "p"),
              alpha = 0.5,
              key = key,
              xlab = "PIB per capita (transformado)",
              ylab = "Expectativa de vida") +
    as.layer(
        xyplot(yhat ~ x, groups = model,
               data = da, type = "l")
    )

xy2 <- xyplot(yhat ~ x | model,
              data = da,
              type = c("l", "g"),
              layout = c(2, 2),
              as.table = TRUE,
              scales = "free",
              strip = strip.custom(
                  factor.levels = leg)) +
    xyplot(y ~ x, data = dados, alpha = 0.6)

print(xy1, split = c(1, 1, 2, 1), more = TRUE)
print(xy2, split = c(2, 1, 2, 1), more = FALSE)

```

Séries de Fourier são comumente utilizadas na análise de séries
temporais, pois tem flexibilidade para ajustar sazonalidade, sua
aplicação aos dados indicados no exemplo parece não ser adequada
conforme pode ser visto na \autoref{fig:curvefourier}, em que os ajustes
dos modelos com $p =$ `r paste(index, collapse=", ")` são exibidos. Como
não é claro um comportamento cíclico nos dados, todos os modelos ajustam
ciclos de forma incorreta, sendo nos modelos para $p$ = 9 e 30 os
ajustes mais discrepantes com ajuste muito incorreto, principalmente
para intervalos com menos observações. Para $p$ = 1 a imposição de forma
da Série de Fourier produz uma curva fora do padrão dos dados para PIB's
padronizados maiores que 0,5.

Assim como o ajuste por polinômios, bastante comum em modelos de
regressão linear aplicados em problemas de predição, a forma do preditor
linear se mantém quando não se tem muitas observações para ajuste,
proporcionando assim, um péssimo poder preditivo para problemas em que a
forma do preditor linear não é adequada, como é o caso deste
exemplo.

***
> _**e) ** Plote o gráfico de valores preditos versus ajustados para p =
  1; p = $p_{esc}$ e p = 30 (não se esqueça de usar o leave-one-out para
  calcular os valores preditos! Caso contrário você terá problemas de
  overfitting novamente). Qual p parece ser o mais razoável?_

```{r predfourier, fig.width=10, fig.height=5, fig.cap="Valores observados versus valores preditos. Traço de valores preditos (esquerda) e observados versus preditos (direita)"}

## Valores preditos vs observado
lista <- results[index]
preds <- do.call(cbind, lapply(lista, function(x) x[["pred"]]))
preds <- cbind(dados[, c("y", "x")], preds)
colnames(preds) <- c("real", "x", index)
preds <- reshape2::melt(as.data.frame(preds), id.vars = c("real", "x"))

preds <- preds[with(preds, order(x)), ]
xy1 <- xyplot(y ~ x, type = c("p", "g"),
              alpha = 0.5, key = key, data = dados) +
    as.layer(
        xyplot(value ~ x,
               groups =  variable,
               data = preds,
               type = "l")
    )

xy2 <- xyplot(real ~ value | variable, data = preds,
              scales = list(x = "free"),
              type = c("p", "g"),
              alpha = 0.5,
              as.table = TRUE,
              layout = c(2, 2),
              ylab = "Observado",
              xlab = "Predito",
              strip = strip.custom(factor.levels = leg),
              panel = function(x, y, subscripts, ...) {
                  panel.xyplot(x, y, ...)
                  panel.abline(0, 1)
              })


print(xy1, split = c(1, 1, 2, 1), more = TRUE)
print(xy2, split = c(2, 1, 2, 1), more = FALSE)

```

Observa-se nos gráficos dos valores preditos versus valores observados,
\autoref{fig:predfourier} à esquerda, que os modelos mais complexos ($p$
= 9 e $p$ = 30) parecem produzir melhores resultados. Todavia, para
alguns valores, cuja a predição é incorreta, a discrepância com relação
ao valor observado é enorme, devido a imposição de sazonalidade do
modelo. Isto posto, podemos interpretar estes bons resultados de
predição para os modelos com $p$ = 9 e $p$ = 30 como sobreajuste, uma
vez que a forma do modelo é incorreta para predição de novas
observações, e o ajuste tentar interpolar as observações. Para os modelos
com $p$ = 1 e $p$ = 3 observa-se claramente que há uma característica
não explicada pelo modelo que prejudica as predições, novamente imposta
pela forma das séries de Fourier.

***
> _**f) ** Quais vantagens e desvantagens de se usar validação cruzada
  do tipo leave-one-out versus o data- splitting?_

Para a avaliação dos modelos ajustados utilizou-se medidas da qualidade
de predição baseadas em validação cruzada do tipo leave-one-out. Essa
estratégia de validação cruzada é computacionalmente intensiva, pois
cada modelo é reajustado $n$ vezes (neste caso $n = 211$), tornando o
procedimento mais lento. Porém ao utilizar a estratégia leave-one-out
todos os dados são utilizados tanto na validação quanto no ajuste do
modelo tornando os resultados gerais. Isso não ocorre quando utilizado
estratégias do tipo data-splitting (holdoult ou k-fold), pois os
resultados ficam condicionados a partição da base, ou seja, há a
variabilidade nos resultados advinda do procedimento de partição,
e.g. ao realizar novamente a avaliação dos modelos via data-splitting os
resultados são, com alta probabilidade, distintos.

***
> _**g) ** Ajuste a regressão Lasso (Frequentista e Bayesiana) e discuta
  os resultados encontrados._

```{r fitlasso, results="hide", cache=TRUE}

##-------------------------------------------
## Lasso Frequentista
library(glmnet)
m0lasso <- cv.glmnet(x = X, y = dados$y,
                     family = "gaussian",
                     alpha = 1, nfolds = 211,
                     grouped = FALSE)

```

```{r fitbayes, results="hide", cache=TRUE}

library(rjags)

model <- "
model {
  ## Verossimilhanca
  for(i in 1:n) {
    y[i] ~ dnorm(mu[i], tau)
    mu[i] <- inprod(X[i, ], beta)
  }
  ## Prioris 1 ordem
  tau ~ dgamma(.1, 1.0E-5)
  for (j in 1:p) {
    beta[j] ~ ddexp(0, lambda)
  }
  ## Prioris 2 ordem
  lambda ~ dgamma(0.1, 0.1)
  ## Tranformacoes
  sigma <- sqrt(1/tau)
}
"

## str(X)
data0 <- list(
    n = nrow(dados),
    p = 1 + ncol(X),
    y = dados$y,
    X = cbind(1, X)
)
init0 <- list(
    tau = 1,
    beta = rep(0, data0$p),
    lambda = m0lasso$lambda.min
)

jagsmodel <- jags.model(
    textConnection(model),
    data = data0,
    inits = init0,
    n.chains = 3,
    n.adapt = 1000
)

amostra <- coda.samples(
    jagsmodel, c("lambda", "beta", "sigma", "mu"),
    n.iter = 10000, thin = 5,
    n.chains = 3,
    n.adapt = 1000)

```

**Ajuste via penalização Lasso**: Sob essa abordagem minimiza-se a
  função de soma de quadrados penalizada da forma $$R(\beta) =
  \sum_{i=1}^n (y_i - \underline{x}_i^t \beta)^2 - \lambda
  \sum_{j=1}^p|\beta_j|$$ em que
  $\underline{x}_i^t=(x_{i1},x_{i2},\ldots,x_{ip})$ são as covariáveis
  de cada observação. A escolha do $\lambda$ ótima, em geral, é
  realizada via validação cruzada.

**Ajuste via especificação Bayesiana**: Sob o paradigma Bayesiano temos
  a penalização da função de verossimilhança realizada por meio de
  prioris dos parâmetros que são assumidas distribuições _Double
  Exponential_ (ou Laplace) de parâmetros 0 e $\lambda$.
  $$\begin{gathered}
  Y \mid X \sim \text{Normal}(\underline{x}_i^t \beta, \sigma^2) \\
  \beta_j \sim \text{Laplace}(0, \lambda), \quad j = 1, 2, \ldots, p
  \end{gathered}$$ em que
  $\underline{x}_i^t=(x_{i1},x_{i2},\ldots,x_{ip})$ são as covariáveis
  de cada observação. Mantendo as inferências sob o paradigma bayesiano
  são dadas prioris para $\sigma^2$ e também, em segundo nível para
  $\lambda$. Assim o tunning do parâmetro $\lambda$ é realizado via
  simulações MCMC, por exemplo.

```{r lambdas, fig.cap="Estimativas do parâmetro lambda pela abordagem de validação cruzada e bayesiana"}

## Coeficientes Lasso
da.lasso <- as.data.frame(
    matrix(c(m0lasso$lambda.min, m0lasso$lambda.min, m0lasso$lambda.1se),
           ncol = 3, nrow = 1))
colnames(da.lasso) <- c("fit", "lower", "upper")

## Coeficientes Bayesiano com intervalo de credibilidade HPD
amlambda <- select_pars(amostra, pars = c("lambda"))
amlambda <- as.mcmc(do.call(c, amlambda))
summary.lambda <- summary(amlambda)

da.bayes <- HPDinterval(amlambda)
da.bayes <- cbind("fit" = summary.lambda$statistics["Mean"],
                  as.data.frame(da.bayes))

## Junta e apresenta as estimativas via lasso e os intervalos de
## credibilidade via abordagem bayesiana
da.all <- rbind(cbind(da.bayes, pars = 1, model = "bayes"),
                cbind(da.lasso, pars = 1, model = "lasso"))
da.all <- da.all[with(da.all, order(pars, model)), ]

key <- list(
    ## corner = c(0.1, 0.9),
    type = "b", divide = 1,
    columns = 2,
    lines = list(pch = c(15, 17), lty = c(1, 0),
                 col = rev(cols[1:2])),
    text = list(c("Intervalo de credibilidade Bayesiano",
                  "Estimativa pontual via penalização Lasso*")))

segplot(
    pars ~ lower + upper,
    centers = fit, groups = model, data = da.all,
    horizontal = TRUE, draw = FALSE,
    key = key,
    pch = c(15, 17),
    lwd = 1.5,
    col = rev(cols[1:2]),
    gap = 0.01,
    ## scales = list(
    ##         x = list(at = 1:60,
    ##                  rot = 90,
    ##                  labels = parse(text = paste0("beta[", 1:60, "]")))
    ## ),
    panel = function(x, y, z, ...) {
        ## panel.abline(v = 1:60, lty = 2, col = "lightgray")
        panel.abline(h = 0, col = 1)
        ## panel.segplot(x, y, z, ...)
        cmpreg::panel.groups.segplot(x, y, z, ...)
    })

```

Na \autoref{fig:lambdas} são exibidos as estimativas do parâmetro
$\lambda$ note que as estimativas pontuais foram próximas. Para os
intervalos exibidos a comparação não é direta uma vez que na abordagem
bayesiana os intervalos são HPD (Highest Posterior Density) e
representam a credibilidade do valor e na abordagem Lasso o limite
superior é dado pelo maior valor de $\lambda$ testado que confere um
erro quadrático médio menor que o limite superior do erro quadrático
médio do $\lambda$ ótimo.

```{r coefs, fig.cap="Coeficientes estimado pela abordagem de penalização Lasso frequentista e bayesiana"}

## Coeficientes Lasso
da.lasso <- as.data.frame(
    matrix(coef(m0lasso, s = "lambda.min"), ncol = 3,
           nrow = length(coef(m0lasso))))
colnames(da.lasso) <- c("fit", "lower", "upper")

## Coeficientes Bayesiano com intervalo de credibilidade HPD
ambeta <- select_pars(amostra, pars = "beta")
ambeta <- as.mcmc(do.call(rbind, ambeta))
summary.beta <- summary(ambeta)

da.bayes <- HPDinterval(ambeta)
da.bayes <- cbind("fit" = summary.beta$statistics[, "Mean"],
                  as.data.frame(da.bayes))

## Junta e apresenta as estimativas via lasso e os intervalos de
## credibilidade via abordagem bayesiana
da.all <- rbind(cbind(da.bayes[-1, ], beta = 1:60, model = "bayes"),
                cbind(da.lasso[-1, ], beta = 1:60, model = "lasso"))
da.all <- da.all[with(da.all, order(beta, model)), ]

key <- list(
    ## corner = c(0.1, 0.9),
    type = "b", divide = 1,
    columns = 2,
    lines = list(pch = c(15, 17), lty = c(1, 0),
                 col = rev(cols[1:2])),
    text = list(c("Intervalo de credibilidade Bayesiano",
                  "Estimativa pontual via penalização Lasso")))

segplot(
    beta ~ lower + upper,
    centers = fit, groups = model, data = da.all,
    horizontal = FALSE, draw = FALSE,
    key = key,
    pch = c(15, 17),
    lwd = 1.5,
    col = rev(cols[1:2]),
    gap = 0.3,
    scales = list(
            x = list(at = 1:60,
                     rot = 90,
                     labels = parse(text = paste0("beta[", 1:60, "]")))
    ),
    panel = function(x, y, z, ...) {
        panel.abline(v = 1:60, lty = 2, col = "lightgray")
        panel.abline(h = 0, col = 1)
        ## panel.segplot(x, y, z, ...)
        cmpreg::panel.groups.segplot(x, y, z, ...)
    })

```

Na \autoref{fig:coefs} são exibidos os coeficientes estimados por ambas
as abordagens com estimativas pontuais para a regressão sob penalização
Lasso e intervalos de credibilidade para o modelo Bayesiano. Note que na
abordagens Bayesiana todos os intervalos compreendem o valor 0 o que
indica que nenhum coeficiente seria necessário em discordância com a
regressão Lasso que indicou 14 coeficientes diferentes de zero.

A vantagem da abordagem Bayesiana é que há um modelo probabilístico
adjacente ao método que fornece inferências mais completas, em contraste
da abordagem frequentista em que o foco consiste somente em predição.

\pagebreak

## Exercício 2 ##

> _Neste exercício você irá implementar algumas técnicas vistas em aula
  para o banco de dados das faces.  O objetivo aqui é conseguir criar
  uma função que consiga predizer para onde uma pessoa está olhando com
  base em uma foto. Iremos aplicar o KNN para esses dados, assim como
  uma regressão linear.  Como não é possível usar o método dos mínimos
  quadrados quando o número de covariáveis é maior que o número de
  observações, para esta segunda etapa iremos usar o lasso._

***
> _**a) ** Leia o banco dadosFacesAltaResolucao.txt. A primeira coluna
  deste banco contém a variável que indica a direção para a qual o
  indivíduo na imagem está olhando. As outras covariáveis contém os
  pixels relativos a essa imagem, que possui dimensão 64
  por 64. Utilizando os comandos fornecidos, plote 5 imagens deste
  banco.\
  Divida o conjunto fornecido em treinamento (aproximadamente
  60% das observações), validação (aproximadamente 20% das observações)
  e teste (aproximadamente 20% das observações).  Utilizaremos o
  conjunto de treinamento e validação para ajustar os modelos. O
  conjunto de teste será utilizado para testar sua performance._

A leitura do conjunto de dados para manipulação no software R é
realizada conforme código abaixo:

```{r dados2, echo=TRUE}

## Leitura dos dados
dados <- read.table("./data/dadosFacesAltaResolucao.txt",
                  header = TRUE, sep = " ")

## Verificando
## str(dados)
dim(dados)

```

Na \autoref{fig:images} são exibidas as seis primeiras imagens do
conjunto da dados para ilustrar como o conjunto é constituído.

```{r images, fig.cap="Seis primeiras imagens representadas no conjunto de dados"}

##----------------------------------------------------------------------
## Plotando as imagens
imagens <- lapply(as.data.frame(t(dados[, -1])),
                  function(x) matrix(x, ncol = 64))
xys <- lapply(1:6, function(x) {
    main <- paste("Figura", x, "(Direção ", dados$y[x], ")")
    xy <- levelplot(imagens[[x]],
                    sub = main,
                    xlab = "",
                    ylab = "",
                    scales = list(draw = FALSE),
                    par.settings = list(
                        layout.heights =
                            list(top.padding = 0,
                                 bottom.padding = 1,
                                 key.sub.padding = 0
                                 ),
                        layout.widths =
                            list(left.padding = 0,
                                 right.padding = 0)))
})

gridExtra::marrangeGrob(xys, nrow = 2, ncol = 3, top = NA)

```
Para a partição do conjunto de dados foi implementada uma rotina que
realiza a divisão da base conforme proporções informadas, a
implementação pode ser vista no
[complemento online](<https://jreduardo.github.io/est171-ml/>) do
trabalho.

```{r part, echo=TRUE}

## Particionando o conjunto de dados
dasplit <- mysplit(dados, percent = c(0.6, 0.2, 0.2),
                   seed = 1994)

## Número de observações em cada partição
sapply(dasplit, dim)

## Atribuindo as partições em objetos de nome sujestivo
da.train <- dasplit[[1]]
da.valid <- dasplit[[2]]
da.teste <- dasplit[[3]]

```

***
> _**b) ** Qual o número de observações? Qual o número de covariáveis? O
  que representa cada covariável?_

Neste conjunto de dados são `r nrow(dados)` observações, que representam
imagens, faces humanas, com a indicação da direção para a qual a face
está virada e da intensidade da coloração em cada pixel. A imagem tem
resolução 64px $x$ 64px, portanto têm-se `r ncol(dados) - 1` covariáveis
que representam a intensidade de coloração em cada pixel.

***
> _**c) ** Para cada observação do conjunto de teste, calcule o
  estimador da função de regressão $r()$ dado pelo método dos $k$
  vizinhos mais próximos com $k = 5$.  Você pode usar as funções vistas
  em aula._

Para esta tarefa utilizou-se o pacote FNN (Fast Nearest Neighbor) do
R. Na \autoref{fig:fitknn} são exibidos as predição provenientes da
aplicação do método KNN com cinco vizinhos. Vale destacar que os valores
exibidos na figura são predições da base de teste utilizando para
treinamento o conjunto de treino e validação.

```{r fitknn, fig.height=5, fig.width=10, fig.cap="Valores preditos pelo método KNN com 5 vizinhos. Valor preditos na ordem do conjunto de teste (esquerda) e preditos versus observados (direita)"}

library(FNN)
train <- rbind(da.train, da.valid)
knn.model <- knn.reg(train = train, test = da.teste,
                     y = train[, "y"], k = 5)

xy1 <- xyplot(knn.model$pred ~ seq_along(knn.model$pred),
              type = c("p", "g"),
              xlab = "Índice da imagem (no conjunto de teste)",
              ylab = "Valor predito para a direção")

xy2 <- xyplot(da.teste[, 1] ~ knn.model$pred,
              type = c("p", "g"),
              xlab = "Valor predito",
              yla = "Valor observado",
              panel = function(x, y, ...) {
                  panel.xyplot(x, y, ...)
                  panel.abline(0, 1)
              })

print(xy1, split = c(1, 1, 2, 1), more = TRUE)
print(xy2, split = c(2, 1, 2, 1), more = FALSE)

```

***
> _**d) ** Utilize validação cruzada (data splitting) para escolher o
  melhor $k$.  Plote $k$ vs Risco estimado._

```{r fitknncv, cache=TRUE}

kseq <- 1:(nrow(da.train))
resultsknn <- lapply(kseq, function(k) {
    model <- knn.reg(train = da.train, test = da.valid,
                     y = da.train[, "y"], k = k)
    pred <- model$pred
    eqs <- (da.valid[, "y"] - pred)^2
    list(eqs = eqs, pred = pred)
})

```

```{r plotknncv, fig.cap="Erros quadráticos médios e medianos na escala logarítimica (linha pontilhada representa a indicação do melhor modelo). Para todos o vizinhos (acima) e apenas para os k's próximos do ótimo (abaixo)."}

## Calcula os erros quadráticos médios
eqs.mean <- sapply(resultsknn, function(x) mean(x[["eqs"]]))
eqs.median <- sapply(resultsknn, function(x) median(x[["eqs"]]))

## Organiza em data.frame
medidas <- data.frame(k = kseq, mean = eqs.mean, median = eqs.median)
da <- reshape2::melt(medidas, id.vars = "k")

## Exibe graficamente
fl <- expression(E(EQM(model[p])),
                 Md(EQM(model[p])))
xy1 <- xyplot(log(value) ~ k | variable,
              type = "S",
              data = da,
              ylab = expression(log(hat(R))),
              as.table = TRUE,
              layout = c(NA, 1),
              scales = "free",
              strip = strip.custom(factor.levels = fl),
              panel = function(x, y, subscripts, ...) {
                  panel.grid()
                  panel.xyplot(x, y, ...)
                  panel.abline(h = min(y, na.rm = TRUE),
                               v = which.min(y),
                               lty = 2)
              })

## Exibe apenas os 8 k's mais próximos (acima e abaixo) do mínimo
medidas.min <- sapply(medidas[, -1], which.min)
index <- c(-8:8) + which.min(eqs.mean)
medidas <- data.frame(k = kseq[index],
                      mean = eqs.mean[index],
                      median = eqs.median[index])
da <- reshape2::melt(medidas, id.vars = "k")

xy2 <- xyplot(log(value) ~ k | variable,
              type = "S",
              data = da,
              ylab = expression(log(hat(R))),
              as.table = TRUE,
              layout = c(NA, 1),
              scales = "free",
              strip = strip.custom(factor.levels = fl),
              panel = function(x, y, subscripts, ...) {
                  panel.grid()
                  panel.xyplot(x, y, ...)
                  panel.abline(h = min(y, na.rm = TRUE),
                               v = which.min(y),
                               lty = 2)
              })

print(xy1, split = c(1, 1, 1, 2), more = TRUE)
print(xy2, split = c(1, 2, 1, 2), more = FALSE)

```

***
> _**e) ** Utilizando o conjunto de teste, estime o risco do KNN para o
  melhor $k$. Plote os valores preditos versus os valores observados
  para o conjunto de teste. Inclua a reta identidade._

```{r predknn, fig.height=5, fig.width=10, fig.cap="Valores preditos pelo método KNN com 10 vizinhos. Preditos versus observados (esquerda) e desvios (direita)."}

## Indicação do melhor algoritmo preditivo
index <- which.min(eqms.median)

## Calibra o método com base no melhor k
train <- rbind(da.train, da.valid)
knn.model <- knn.reg(train = train, test = da.teste,
                     y = train[, "y"], k = kseq[index])

##
xy1 <- xyplot(da.teste[, 1] ~ knn.model$pred,
              type = c("p", "g"),
              panel = function(x, y, ...) {
                  panel.xyplot(x, y, ...)
                  panel.abline(0, 1)
              })

xy2 <- xyplot(da.teste[, 1] - knn.model$pred ~ seq_along(da.teste[, 1]),
              type = c("p", "g", "smooth"),
              panel = function(x, y, ...) {
                  panel.xyplot(x, y, ...)
                  panel.abline(h = 0, lty = 2, col = cols[2])
              })

print(xy1, split = c(1, 1, 2, 1), more = TRUE)
print(xy2, split = c(2, 1, 2, 1), more = FALSE)

```

***
> _**f) ** Ajuste uma regressão linear para os dados usando o conjunto
  de treinamento mais o de validação via lasso (lembre-se que a função
  que ajusta o lasso no R já faz validação cruzada automaticamente: ao
  contrário do KNN, neste caso não é necessário separar os dados em
  treinamento e validação). Qual o lambda escolhido? Plote $\lambda$ vs
  Risco estimado._

```{r fitlassofaces, cache=TRUE}

##----------------------------------------------------------------------
## Regressão com penalização do tipo Lasso
library(glmnet)
## Validação leave-one-out (demorado!)
train <- rbind(da.train, da.valid)
lasso.model <- cv.glmnet(x = as.matrix(train[, -1]), y = train[, "y"],
                         family = "gaussian", alpha = 1,
                         nfolds = nrow(train), grouped = FALSE)

```

Para ajuste da regressão linear sob penalização do tipo Lasso
utilizou-se a validação cruzada do tipo leave-one-out para estudo do
parâmetro $\lambda$ de penalização. Os resultados da validação cruzada
são exibidos na \autoref{plotlassofaces} onde têm-se os erros
quadráticos médios em função dos $\lambda$'s na escala logarítmica. O
$\lambda$ que minimiza o erro quadrático médio é
`r lasso.model$lambda.min` e o maior $\lambda$, cujo erro quadrático
médio é menor que o limite superior do erro sob o $\lambda$ ótimo é
`r lasso.model$lambda.1se`.

```{r plotlassofaces, fig.cap="Lambdas versus erros quadráticos médios"}

plot(lasso.model)

```

***
> _**g) ** Utilizando o conjunto de teste, estime o risco do lasso para
  o melhor $\lambda$. Plote os valores preditos versus os valores
  observados para o conjunto de teste. Inclua a reta identidade._

```{r predlasso, fig.height=5, fig.width=10, fig.cap="Valores preditos pelo método Lasso. Preditos versus observados (esquerda) e desvios (direita)."}

pred.lasso <- predict(lasso.model, newx = as.matrix(da.teste[, -1]),
                      s = "lambda.min")

xy1 <- xyplot(da.teste[, 1] ~ pred.lasso,
              type = c("p", "g"),
              xlab = "Valores preditos",
              ylab = "Valores observados",
              panel = function(x, y, ...) {
                  panel.xyplot(x, y, ...)
                  panel.abline(0, 1)
              })

xy2 <- xyplot(da.teste[, 1] - pred.lasso ~ seq_along(da.teste[, 1]),
              type = c("p", "g", "smooth"),
              xlab = "Indice da imagem (no conjunto de teste)",
              ylab = "Desvios (observado - predito)",
              panel = function(x, y, ...) {
                  panel.xyplot(x, y, ...)
                  panel.abline(h = 0, lty = 2, col = cols[2])
              })

print(xy1, split = c(1, 1, 2, 1), more = TRUE)
print(xy2, split = c(2, 1, 2, 1), more = FALSE)

```

***
> _**h) ** Quantos coeficientes foram estimados como sendo zero?_

```{r}

ncoef <- sum(as.matrix(coef(lasso.model, s = "lambda.min")) != 0)

```

Via penalização Lasso com $\lambda$= `r lasso.model$lambda.min` foram
apenas `r ncoef` coeficientes de `r ncol(dados)-1`, cujo valor não foi
zerado.

***
> _**i) ** Qual modelo teve melhores resultados: regressão linear via
  lasso ou KNN?_

```{r compare, fig.cap="Comparação dos métodos preditivos KNN e regressão Lasso via erros quadráticos"}

pred.knn <- knn.reg(train = train, test = da.teste,
                     y = train[, "y"], k = kseq[index])$pred
eqm.knn <- (da.teste[, 1] - pred.knn)^2
eqm.lasso <- (da.teste[, 1] - pred.lasso)^2

da <- data.frame(eqm = c(eqm.knn, eqm.lasso),
                 model = rep(c("knn", "lasso"),
                             each = nrow(da.teste)))

xyplot(eqm ~ model,
       data = da,
       ylab = expression(Erro~Quadrático),
       xlab = "Método",
       scales = list(y = list(log = TRUE)),
       panel = function(x, y, ...) {
           panel.grid(h = -1, v = 0)
           panel.xyplot(x = as.integer(x) - 0.05, y = y,
                        col = "gray60", alpha = 0.7, cex = 0.8,
                        jitter.x = TRUE, factor = 0.1, ...)
           panel.bwplot(x = as.integer(x) + 0.05, y = y,
                        horizontal = FALSE, box.width = 0.1)
           means <- tapply(y, x, mean)
           panel.points(y = means, x = unique(as.integer(x)) + 0.05,
                        pch = 15)
       })

```

Ambos os métodos são meramente preditivos, ou seja, são algoritmos
numéricos em que não se faz inferências a não ser a predição, pois não
assume-se modelo, verossimilhança, etc. Portanto, para a comparação dos
métodos utilizou-se o erro quadrático de predição no conjunto de
teste. Os resultados para comparação são exibidos na
\autoref{fig:compare}. Note que os erros são, em média, menores para o
KNN favorecendo esse método em detrimento da regressão Lasso. Outra
característica observada na figura que favorece o KNN é a dispersão dos
erros, que é menor para o KNN. Isso mostra que o método KNN, aplicado a
esse conjunto de dados, proporcionou melhores resultados que o método de
regressão sob penalização Lasso.

## Material suplementar ##

Todos os códigos (para manipulação, ajustes e gráficos) exibidos neste
trabalho estão disponíveis no endereço
<https://jreduardo.github.io/est171-ml/>.
